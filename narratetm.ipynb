{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPhpRvLU3i+V6x+NUExAI0h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/localecho/Python-GUI-examples/blob/master/narratetm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQc1tf7kLHBx"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# Load a pre-trained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Function to load an image from a URL\n",
        "def load_image_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    image = Image.open(requests.get(url, stream=True).raw)\n",
        "    image = F.to_tensor(image).unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "# Example image URL (Replace with your own URL or use a local image)\n",
        "image_url = \"https://thumbs.dreamstime.com/b/flat-vector-social-media-internet-infographic-icon-style-online-content-sharing-lifestyle-infographics-set-concept-collage-stylish-59052315.jpg\"\n",
        "\n",
        "\n",
        "image = load_image_from_url(image_url)\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    prediction = model(image)\n",
        "\n",
        "# Correct way to process predictions\n",
        "boxes = prediction[0]['boxes']\n",
        "labels = prediction[0]['labels']\n",
        "scores = prediction[0]['scores']\n",
        "\n",
        "# Now, you can iterate over these tensors if you need to process individual detections\n",
        "for i in range(len(boxes)):\n",
        "    box = boxes[i]\n",
        "    label = labels[i]\n",
        "    score = scores[i]\n",
        "    print(f\"Box: {box}, Label: {label}, Score: {score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib torchvision pillow openai\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key here\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "69iLQHABU_gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets Visualize\n",
        "# note to BH: you can change the threshhold at the bottom\n",
        "\n",
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Function to convert tensor to PIL Image\n",
        "def tensor_to_pil(tensor):\n",
        "    return T.ToPILImage()(tensor.squeeze_(0))\n",
        "\n",
        "# Assuming 'image' is your PIL Image and 'prediction' is the output from the model\n",
        "img = tensor_to_pil(image)  # Convert the tensor image back to PIL Image if necessary\n",
        "\n",
        "# Create a matplotlib figure\n",
        "fig, ax = plt.subplots(1, figsize=(12, 9))\n",
        "ax.imshow(img)\n",
        "\n",
        "# Retrieve the COCO categories from a pre-defined list or file\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
        "    'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass',\n",
        "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
        "    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "# Continuing from the previously defined object_attributes dictionary\n",
        "object_attributes = {\n",
        "    '__background__': {\n",
        "    'bottle': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'wine glass': {'emotion': 'neutral', 'age': 'new', 'color': 'clear'},\n",
        "    'cup': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'fork': {'emotion': 'neutral', 'age': 'variable', 'color': 'silver'},\n",
        "    'knife': {'emotion': 'neutral', 'age': 'variable', 'color': 'silver'},\n",
        "    'spoon': {'emotion': 'neutral', 'age': 'variable', 'color': 'silver'},\n",
        "    'bowl': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'banana': {'emotion': 'happy', 'age': 'ripe', 'color': 'yellow'},\n",
        "    'apple': {'emotion': 'happy', 'age': 'fresh', 'color': 'red/green'},\n",
        "    'sandwich': {'emotion': 'neutral', 'age': 'fresh', 'color': 'variable'},\n",
        "    'orange': {'emotion': 'happy', 'age': 'ripe', 'color': 'orange'},\n",
        "    'broccoli': {'emotion': 'neutral', 'age': 'fresh', 'color': 'green'},\n",
        "    'carrot': {'emotion': 'happy', 'age': 'fresh', 'color': 'orange'},\n",
        "    'hot dog': {'emotion': 'happy', 'age': 'cooked', 'color': 'variable'},\n",
        "    'pizza': {'emotion': 'happy', 'age': 'cooked', 'color': 'variable'},\n",
        "    'donut': {'emotion': 'happy', 'age': 'fresh', 'color': 'variable'},\n",
        "    'cake': {'emotion': 'happy', 'age': 'fresh', 'color': 'variable'},\n",
        "    'chair': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'couch': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'potted plant': {'emotion': 'happy', 'age': 'growing', 'color': 'green'},\n",
        "    'bed': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'dining table': {'emotion': 'neutral', 'age': 'variable', 'color': 'brown'},\n",
        "    'toilet': {'emotion': 'neutral', 'age': 'variable', 'color': 'white'},\n",
        "    'tv': {'emotion': 'neutral', 'age': 'new', 'color': 'black'},\n",
        "    'laptop': {'emotion': 'neutral', 'age': 'new', 'color': 'silver/black'},\n",
        "    'mouse': {'emotion': 'neutral', 'age': 'new', 'color': 'black'},\n",
        "    'remote': {'emotion': 'neutral', 'age': 'variable', 'color': 'black'},\n",
        "    'keyboard': {'emotion': 'neutral', 'age': 'new', 'color': 'black'},\n",
        "    'cell phone': {'emotion': 'neutral', 'age': 'new', 'color': 'black'},\n",
        "    'microwave': {'emotion': 'neutral', 'age': 'new', 'color': 'silver'},\n",
        "    'oven': {'emotion': 'neutral', 'age': 'variable', 'color': 'black/silver'},\n",
        "    'toaster': {'emotion': 'neutral', 'age': 'new', 'color': 'silver'},\n",
        "    'sink': {'emotion': 'neutral', 'age': 'variable', 'color': 'silver'},\n",
        "    'refrigerator': {'emotion': 'neutral', 'age': 'new', 'color': 'white/silver'},\n",
        "    'book': {'emotion': 'happy', 'age': 'variable', 'color': 'variable'},\n",
        "    'clock': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'vase': {'emotion': 'neutral', 'age': 'new', 'color': 'variable'},\n",
        "    'scissors': {'emotion': 'neutral', 'age': 'new', 'color': 'silver'},\n",
        "    'teddy bear': {'emotion': 'happy', 'age': 'new', 'color': 'brown'},\n",
        "    'hair drier': {'emotion': 'neutral', 'age': 'new', 'color': 'black'},\n",
        "    'toothbrush': {'emotion': 'neutral', 'age': 'new', 'color': 'variable'},\n",
        "}}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Loop through each detection in the prediction\n",
        "for box, label, score in zip(prediction[0]['boxes'], prediction[0]['labels'], prediction[0]['scores']):\n",
        "    if score > 0.1:  # Filter out detections with low confidence\n",
        "        x, y, xmax, ymax = box\n",
        "        rect = patches.Rectangle((x, y), xmax - x, ymax - y, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x, y, f\"{COCO_INSTANCE_CATEGORY_NAMES[label]}: {score:.2f}\", verticalalignment='top', color='white', fontsize=12, weight='bold', backgroundcolor=\"r\")\n",
        "\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PziOcM07Mb3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial setup for a UML diagram (text-based representation)\n",
        "\n",
        "\n",
        "detected_objects = []\n",
        "confidence_threshold = 0.4  # Adjust this threshold as needed\n",
        "\n",
        "for box, label, score in zip(prediction[0]['boxes'], prediction[0]['labels'], prediction[0]['scores']):\n",
        "    if score > confidence_threshold:\n",
        "        detected_objects.append({\n",
        "            \"name\": COCO_INSTANCE_CATEGORY_NAMES[label],\n",
        "            \"confidence\": score.item()  # Convert to Python number if it's a tensor\n",
        "        })\n",
        "\n",
        "# Example print to verify detected objects\n",
        "for obj in detected_objects:\n",
        "    print(f\"Detected {obj['name']} with confidence {obj['confidence']:.2f}\")\n"
      ],
      "metadata": {
        "id": "eUl1IFoCT3Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial setup for a UML diagram (text-based representation)\n",
        "uml_classes = {obj['name']: {\"attributes\": []} for obj in detected_objects}\n",
        "\n",
        "def generate_uml_text(uml_classes):\n",
        "    uml_text = \"classDiagram\\n\"\n",
        "    for obj_name, details in uml_classes.items():\n",
        "        uml_text += f\"    class {obj_name} {{\\n\"\n",
        "        for attr in details[\"attributes\"]:\n",
        "            uml_text += f\"        {attr}\\n\"\n",
        "        uml_text += \"    }\\n\"\n",
        "    return uml_text\n",
        "\n",
        "# Generate and print initial UML diagram structure\n",
        "uml_text = generate_uml_text(uml_classes)\n",
        "print(uml_text)\n"
      ],
      "metadata": {
        "id": "VX5DBiGYUTT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correcting the key used for accessing object names in generate_uml_text\n",
        "def generate_uml_text(detected_objects):\n",
        "    uml_text = \"classDiagram\\n\"\n",
        "    for obj in detected_objects:\n",
        "        obj_name = obj['name']  # Use 'name' to access the object's identifying label\n",
        "        attributes = obj['attributes']  # Access the enriched attributes\n",
        "        uml_text += f\"    class {obj_name.replace(' ', '').replace('-', '')} {{\\n\"  # Adjust for valid Mermaid class names\n",
        "        for attr_name, attr_value in attributes.items():\n",
        "            # Format attributes for UML diagram text\n",
        "            uml_text += f\"        {attr_name}: {attr_value}\\n\"\n",
        "        uml_text += \"    }\\n\"\n",
        "    return uml_text\n",
        "\n",
        "# Generate and print the UML diagram text with the corrected key usage\n",
        "uml_text = generate_uml_text(detected_objects)\n",
        "print(uml_text)\n"
      ],
      "metadata": {
        "id": "SmFadNhnUZta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mermaid_code(detected_objects):\n",
        "    mermaid_code = \"classDiagram\\n\"\n",
        "    for obj in detected_objects:\n",
        "        obj_name = obj['name'].replace(\" \", \"\").replace(\"-\", \"\")  # Adjusting for Mermaid compatibility\n",
        "        attributes = obj.get('attributes', {})\n",
        "        mermaid_code += f\"    class {obj_name} {{\\n\"\n",
        "        for attr_name, attr_value in attributes.items():\n",
        "            # Formatting for Mermaid compatibility\n",
        "            mermaid_code += f\"        {attr_name} : {attr_value}\\n\"\n",
        "        mermaid_code += \"    }\\n\"\n",
        "    return mermaid_code\n",
        "\n",
        "# Assuming detected_objects is already populated and enriched with attributes\n",
        "mermaid_code = generate_mermaid_code(detected_objects)\n",
        "print(mermaid_code)\n"
      ],
      "metadata": {
        "id": "Hr65XfCmwBbw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
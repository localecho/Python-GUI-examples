{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOLsiFV6ztVceJCqLMmFaT3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/localecho/Python-GUI-examples/blob/master/Copy_of_Copy_of_crewai_jobprep_v1_012224.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning multi-line string to text\n",
        "text = \"\"\"\n",
        "User\n",
        "I have an art idea.. I want two heads with speakers in their mouths to have a conversation about politics (obviously conservative and libera) via chatgpt talking to one another. i have a few mac minis and apis to real sounding audio text to emotions. give me a technical rundown waht i need\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0XjQn8EV3aEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVf-PqESLOob",
        "outputId": "fca3d330-706d-440a-a968-f4265b7c2a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crewai in /usr/local/lib/python3.10/dist-packages (0.1.32)\n",
            "Requirement already satisfied: langchain<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (0.1.4)\n",
            "Requirement already satisfied: langchain-openai<0.0.3,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (0.0.2.post1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.10.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.5.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (0.0.16)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (0.1.16)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (0.0.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->crewai) (8.2.3)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai<0.0.3,>=0.0.2->crewai) (0.5.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (0.26.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (4.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (2.14.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->crewai) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->crewai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->crewai) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->crewai) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->crewai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.7.1->crewai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.7.1->crewai) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->crewai) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->crewai) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.7.1->crewai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.7.1->crewai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.7.1->crewai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.0->crewai) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain<0.2.0,>=0.1.0->crewai) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->crewai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->crewai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.0->crewai) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai<0.0.3,>=0.0.2->crewai) (2023.6.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->crewai) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup\n",
        "!pip install crewai\n",
        "\n",
        "# Importing necessary libraries for CrewAI\n",
        "import os\n",
        "\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain.agents import Tool\n",
        "from langchain.utilities import GoogleSerperAPIWrapper\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Setting up environment variables for API keys\n",
        "# Replace 'Your_Key' with your actual API keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "os.environ[\"SERPER_API_KEY\"] = \"4e153c0ec14a8c5726bfcd2a8f0ea30c8073cb92\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_context_and_question(topic):\n",
        "    # Define a template for context and question\n",
        "    context_template = f\"\"\"\n",
        "    [This is a background about {topic}. It includes key information about personalized education strategies,\n",
        "    diverse learning paths for different age groups, and the integration of modern educational technologies.\n",
        "    Notable contributions from esteemed universities and leading research in the field are also considered.]\n",
        "    \"\"\"\n",
        "\n",
        "    question_template = f\"\"\"\n",
        "    [What are the main challenges and opportunities associated with developing {topic},\n",
        "    especially when considering individual learning preferences, technological advancements,\n",
        "    and cutting-edge research from academic institutions?]\n",
        "    \"\"\"\n",
        "\n",
        "    # Return the formatted context and question\n",
        "    return context_template, question_template\n",
        "\n",
        "# Print the content of the text variable\n",
        "print(text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy9J74ToL-E7",
        "outputId": "21d3c72c-5c47-49d5-ff8a-44d8ed92c8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are tasked with completing a Python script that scrapes musical scores of Scriabin's compositions from various online sources. The primary objective is to gather a comprehensive dataset that will be used to analyze Scriabin's musical style and generate MIDI files. Your role is to implement specific functionalities within the script to ensure efficient data collection and processing. Follow these guidelines:\n",
            "\n",
            "# Import necessary libraries\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "# Use Selenium if necessary for dynamic websites\n",
            "# from selenium import webdriver\n",
            "\n",
            "# Function to scrape scores from a single website\n",
            "def scrape_website(url):\n",
            "    \"\"\n",
            "    Scrapes musical scores from the given URL.\n",
            "    Args:\n",
            "    url (str): URL of the website to scrape.\n",
            "\n",
            "    Returns:\n",
            "    list: A list of musical scores and their details.\n",
            "    \"\"\n",
            "    # Add code to make an HTTP request to the website\n",
            "    response = requests.get(url)\n",
            "    \n",
            "    # Add error handling for the request\n",
            "    if response.status_code != 200:\n",
            "        print(f\"Failed to retrieve data from {url}\")\n",
            "        return []\n",
            "\n",
            "    # Parse the webpage content\n",
            "    soup = BeautifulSoup(response.text, 'html.parser')\n",
            "\n",
            "    # Add code to extract the relevant data from the page\n",
            "    # This will depend on the structure of the webpage\n",
            "    # For example, find all elements that contain score information\n",
            "    # scores = soup.find_all('...')\n",
            "\n",
            "    # Iterate over the extracted elements and collect necessary data\n",
            "    # collected_scores = []\n",
            "    # for score in scores:\n",
            "    #     # Extract data like title, composer, link to the score, etc.\n",
            "    #     # title = score.find('...').text\n",
            "    #     # Add extracted data to the collected_scores list\n",
            "    #     # collected_scores.append({...})\n",
            "\n",
            "    # Return the collected scores\n",
            "    return collected_scores\n",
            "\n",
            "# List of URLs to scrape\n",
            "urls = [\n",
            "    'https://imslp.org',\n",
            "    'https://musescore.com',\n",
            "    # Add other URLs here\n",
            "]\n",
            "\n",
            "# Main function to scrape scores from all websites\n",
            "def main():\n",
            "    all_scores = []\n",
            "    for url in urls:\n",
            "        scores = scrape_website(url)\n",
            "        all_scores.extend(scores)\n",
            "\n",
            "    # Add code to save or process the collected scores\n",
            "    # For example, saving to a CSV file\n",
            "    # save_to_csv(all_scores)\n",
            "\n",
            "    # Print or return the final collected data\n",
            "    print(all_scores)\n",
            "\n",
            "# Entry point of the script\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "\n",
            "\n",
            "Note to CrewAI Agent: This is a coding-centric project. More comprehensive and efficient code implementations will achieve higher scores. Aim for a 5-star rating by focusing on code quality and adherence to the rubric.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from nltk.util import ngrams\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import numpy as np\n",
        "\n",
        "def extract_themes_pro(text, num_themes=1000):\n",
        "    \"\"\"\n",
        "    Analyze a combined text of context and question to extract key themes using BERT embeddings and multi-dimensional Euclidean distances.\n",
        "    The text should be formatted as 'context|question'.\n",
        "\n",
        "    Args:\n",
        "    text (str): The combined context and question, separated by a '|'.\n",
        "    num_themes (int): Number of themes to extract, default is 1000.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of the most prominent themes.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize BERT tokenizer and model\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
        "\n",
        "    # Convert tokens to BERT embeddings\n",
        "    inputs = tokenizer(filtered_tokens, return_tensors='pt', padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "\n",
        "    # Calculate Euclidean distances between embeddings\n",
        "    dist_matrix = euclidean_distances(embeddings)\n",
        "\n",
        "    # Extract themes based on the closest distances\n",
        "    idx_closest = np.argsort(dist_matrix, axis=1)[:, :num_themes]\n",
        "    themes = [filtered_tokens[i] for i in idx_closest.flatten()]\n",
        "\n",
        "    # Ensure uniqueness and return\n",
        "    unique_themes = list(set(themes))\n",
        "    return unique_themes[:num_themes]\n"
      ],
      "metadata": {
        "id": "xXai3dIgqz_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Ensure NLTK resources are available\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import numpy as np\n",
        "\n",
        "def extract_themes_pro_bert(text, num_themes=1000):\n",
        "    \"\"\"\n",
        "    Analyze the text to extract key themes using BERT embeddings and multi-dimensional Euclidean distances.\n",
        "\n",
        "    Args:\n",
        "    text (str): The text for theme extraction.\n",
        "    num_themes (int): Number of themes to extract, default is 1000.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of the most prominent themes.\n",
        "    \"\"\"\n",
        "    # Initialize BERT tokenizer and model\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Tokenize and remove stopwords from the text\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
        "\n",
        "    # Convert tokens to BERT embeddings\n",
        "    inputs = tokenizer(filtered_tokens, return_tensors='pt', padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "\n",
        "    # Calculate Euclidean distances between embeddings\n",
        "    dist_matrix = euclidean_distances(embeddings)\n",
        "\n",
        "    # Extract themes based on the closest distances\n",
        "    idx_closest = np.argsort(dist_matrix, axis=1)[:, :num_themes]\n",
        "    themes = [filtered_tokens[i] for i in idx_closest.flatten()]\n",
        "\n",
        "    # Ensure uniqueness and return\n",
        "    unique_themes = list(set(themes))\n",
        "    return unique_themes[:num_themes]\n"
      ],
      "metadata": {
        "id": "Uf5k2hN5xXBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "701bfa99-75e2-4efc-d477-8860d2d37c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def match_job_titles(themes):\n",
        "    \"\"\"\n",
        "    Match extracted themes with appropriate job titles.\n",
        "\n",
        "    Args:\n",
        "    themes (list): List of themes extracted from text.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of matched job titles.\n",
        "    \"\"\"\n",
        "    # Example job titles categorization (can be expanded based on the resources)\n",
        "    job_titles = {\n",
        "        \"marketing\": [\"Digital Marketing Director\", \"Senior Marketing Strategist\"],\n",
        "        \"cybersecurity\": [\"Security Analyst\", \"Information Security Manager\"],\n",
        "        \"data science\": [\"Data Scientist\", \"Data Analyst\"],\n",
        "        \"finance\": [\"Financial Analyst\", \"Corporate Finance Manager\"],\n",
        "        \"sales\": [\"Sales Manager\", \"Account Executive\"],\n",
        "        \"hr\": [\"HR Manager\", \"Talent Acquisition Specialist\"],\n",
        "        # Add more categories and titles as needed\n",
        "    }\n",
        "\n",
        "    matched_titles = []\n",
        "    for theme in themes:\n",
        "        # Example logic to match themes with job titles\n",
        "        # This can be refined based on the specific themes and available job titles\n",
        "        category = theme.lower()\n",
        "        if category in job_titles:\n",
        "            matched_titles.extend(job_titles[category])\n",
        "        else:\n",
        "            # Handling unmatched themes\n",
        "            matched_titles.append(\"Specialist in \" + theme.title())\n",
        "\n",
        "    return matched_titles\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q3qQ1fxrXKlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble the AI Crew\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "import random\n",
        "\n",
        "# Function to analyze context and question for key themes\n",
        "\n",
        "# Extracting themes\n",
        "themes_bert = extract_themes_pro_bert(text)\n",
        "themes_pro =  extract_themes_pro(text)\n",
        "themes = themes_bert + themes_pro\n",
        "\n",
        "\n",
        "# Number of agents to create\n",
        "num_agents = 200\n",
        "\n",
        "# Creating a list to hold all agents\n",
        "agents = []\n",
        "# Loop to create each agent\n",
        "for i in range(num_agents):\n",
        "    theme_index = i % len(themes)\n",
        "    role = f'Agent with expertise in {themes[theme_index]}'\n",
        "    goal = f'Provide insights on {themes[theme_index]} related to the question'\n",
        "    backstory = f'Agent {i+1} specializing in {themes[theme_index]}.'\n",
        "\n",
        "    # Creating a wildcard agent with contrasting characteristics\n",
        "    if i == num_agents - 1:\n",
        "        role = 'Wildcard Agent with Diverse Perspective'\n",
        "        goal = 'Challenge the conventional thinking and provide alternative viewpoints'\n",
        "        backstory = 'An agent known for unconventional approaches and thinking outside the box.'\n",
        "\n",
        "    # Creating an agent\n",
        "    agent = Agent(\n",
        "        role=role,\n",
        "        goal=goal,\n",
        "        backstory=backstory,\n",
        "        verbose=True\n",
        "    )\n",
        "    agents.append(agent)\n",
        "\n",
        "# Displaying the created agents\n",
        "for agent in agents:\n",
        "    print(f'Agent Role: {agent.role}, Goal: {agent.goal}, Backstory: {agent.backstory}')\n"
      ],
      "metadata": {
        "id": "eIWiASsgMKWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20c2f58-e709-4aac-f5d1-fdae4f0409fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent Role: Agent with expertise in specific, Goal: Provide insights on specific related to the question, Backstory: Agent 1 specializing in specific.\n",
            "Agent Role: Agent with expertise in def, Goal: Provide insights on def related to the question, Backstory: Agent 2 specializing in def.\n",
            "Agent Role: Agent with expertise in example, Goal: Provide insights on example related to the question, Backstory: Agent 3 specializing in example.\n",
            "Agent Role: Agent with expertise in webpage, Goal: Provide insights on webpage related to the question, Backstory: Agent 4 specializing in webpage.\n",
            "Agent Role: Agent with expertise in urls, Goal: Provide insights on urls related to the question, Backstory: Agent 5 specializing in urls.\n",
            "Agent Role: Agent with expertise in request, Goal: Provide insights on request related to the question, Backstory: Agent 6 specializing in request.\n",
            "Agent Role: Agent with expertise in final, Goal: Provide insights on final related to the question, Backstory: Agent 7 specializing in final.\n",
            "Agent Role: Agent with expertise in objective, Goal: Provide insights on objective related to the question, Backstory: Agent 8 specializing in objective.\n",
            "Agent Role: Agent with expertise in make, Goal: Provide insights on make related to the question, Backstory: Agent 9 specializing in make.\n",
            "Agent Role: Agent with expertise in page, Goal: Provide insights on page related to the question, Backstory: Agent 10 specializing in page.\n",
            "Agent Role: Agent with expertise in scrape, Goal: Provide insights on scrape related to the question, Backstory: Agent 11 specializing in scrape.\n",
            "Agent Role: Agent with expertise in comprehensive, Goal: Provide insights on comprehensive related to the question, Backstory: Agent 12 specializing in comprehensive.\n",
            "Agent Role: Agent with expertise in parse, Goal: Provide insights on parse related to the question, Backstory: Agent 13 specializing in parse.\n",
            "Agent Role: Agent with expertise in aim, Goal: Provide insights on aim related to the question, Backstory: Agent 14 specializing in aim.\n",
            "Agent Role: Agent with expertise in rubric, Goal: Provide insights on rubric related to the question, Backstory: Agent 15 specializing in rubric.\n",
            "Agent Role: Agent with expertise in requests, Goal: Provide insights on requests related to the question, Backstory: Agent 16 specializing in requests.\n",
            "Agent Role: Agent with expertise in online, Goal: Provide insights on online related to the question, Backstory: Agent 17 specializing in online.\n",
            "Agent Role: Agent with expertise in beautifulsoup, Goal: Provide insights on beautifulsoup related to the question, Backstory: Agent 18 specializing in beautifulsoup.\n",
            "Agent Role: Agent with expertise in return, Goal: Provide insights on return related to the question, Backstory: Agent 19 specializing in return.\n",
            "Agent Role: Agent with expertise in url, Goal: Provide insights on url related to the question, Backstory: Agent 20 specializing in url.\n",
            "Agent Role: Agent with expertise in various, Goal: Provide insights on various related to the question, Backstory: Agent 21 specializing in various.\n",
            "Agent Role: Agent with expertise in files, Goal: Provide insights on files related to the question, Backstory: Agent 22 specializing in files.\n",
            "Agent Role: Agent with expertise in ensure, Goal: Provide insights on ensure related to the question, Backstory: Agent 23 specializing in ensure.\n",
            "Agent Role: Agent with expertise in website, Goal: Provide insights on website related to the question, Backstory: Agent 24 specializing in website.\n",
            "Agent Role: Agent with expertise in gather, Goal: Provide insights on gather related to the question, Backstory: Agent 25 specializing in gather.\n",
            "Agent Role: Agent with expertise in implement, Goal: Provide insights on implement related to the question, Backstory: Agent 26 specializing in implement.\n",
            "Agent Role: Agent with expertise in collection, Goal: Provide insights on collection related to the question, Backstory: Agent 27 specializing in collection.\n",
            "Agent Role: Agent with expertise in elements, Goal: Provide insights on elements related to the question, Backstory: Agent 28 specializing in elements.\n",
            "Agent Role: Agent with expertise in necessary, Goal: Provide insights on necessary related to the question, Backstory: Agent 29 specializing in necessary.\n",
            "Agent Role: Agent with expertise in failed, Goal: Provide insights on failed related to the question, Backstory: Agent 30 specializing in failed.\n",
            "Agent Role: Agent with expertise in import, Goal: Provide insights on import related to the question, Backstory: Agent 31 specializing in import.\n",
            "Agent Role: Agent with expertise in structure, Goal: Provide insights on structure related to the question, Backstory: Agent 32 specializing in structure.\n",
            "Agent Role: Agent with expertise in function, Goal: Provide insights on function related to the question, Backstory: Agent 33 specializing in function.\n",
            "Agent Role: Agent with expertise in midi, Goal: Provide insights on midi related to the question, Backstory: Agent 34 specializing in midi.\n",
            "Agent Role: Agent with expertise in sources, Goal: Provide insights on sources related to the question, Backstory: Agent 35 specializing in sources.\n",
            "Agent Role: Agent with expertise in extract, Goal: Provide insights on extract related to the question, Backstory: Agent 36 specializing in extract.\n",
            "Agent Role: Agent with expertise in implementations, Goal: Provide insights on implementations related to the question, Backstory: Agent 37 specializing in implementations.\n",
            "Agent Role: Agent with expertise in focusing, Goal: Provide insights on focusing related to the question, Backstory: Agent 38 specializing in focusing.\n",
            "Agent Role: Agent with expertise in processing, Goal: Provide insights on processing related to the question, Backstory: Agent 39 specializing in processing.\n",
            "Agent Role: Agent with expertise in compositions, Goal: Provide insights on compositions related to the question, Backstory: Agent 40 specializing in compositions.\n",
            "Agent Role: Agent with expertise in data, Goal: Provide insights on data related to the question, Backstory: Agent 41 specializing in data.\n",
            "Agent Role: Agent with expertise in collect, Goal: Provide insights on collect related to the question, Backstory: Agent 42 specializing in collect.\n",
            "Agent Role: Agent with expertise in given, Goal: Provide insights on given related to the question, Backstory: Agent 43 specializing in given.\n",
            "Agent Role: Agent with expertise in etc, Goal: Provide insights on etc related to the question, Backstory: Agent 44 specializing in etc.\n",
            "Agent Role: Agent with expertise in soup, Goal: Provide insights on soup related to the question, Backstory: Agent 45 specializing in soup.\n",
            "Agent Role: Agent with expertise in entry, Goal: Provide insights on entry related to the question, Backstory: Agent 46 specializing in entry.\n",
            "Agent Role: Agent with expertise in retrieve, Goal: Provide insights on retrieve related to the question, Backstory: Agent 47 specializing in retrieve.\n",
            "Agent Role: Agent with expertise in quality, Goal: Provide insights on quality related to the question, Backstory: Agent 48 specializing in quality.\n",
            "Agent Role: Agent with expertise in within, Goal: Provide insights on within related to the question, Backstory: Agent 49 specializing in within.\n",
            "Agent Role: Agent with expertise in link, Goal: Provide insights on link related to the question, Backstory: Agent 50 specializing in link.\n",
            "Agent Role: Agent with expertise in achieve, Goal: Provide insights on achieve related to the question, Backstory: Agent 51 specializing in achieve.\n",
            "Agent Role: Agent with expertise in find, Goal: Provide insights on find related to the question, Backstory: Agent 52 specializing in find.\n",
            "Agent Role: Agent with expertise in role, Goal: Provide insights on role related to the question, Backstory: Agent 53 specializing in role.\n",
            "Agent Role: Agent with expertise in guidelines, Goal: Provide insights on guidelines related to the question, Backstory: Agent 54 specializing in guidelines.\n",
            "Agent Role: Agent with expertise in f, Goal: Provide insights on f related to the question, Backstory: Agent 55 specializing in f.\n",
            "Agent Role: Agent with expertise in point, Goal: Provide insights on point related to the question, Backstory: Agent 56 specializing in point.\n",
            "Agent Role: Agent with expertise in add, Goal: Provide insights on add related to the question, Backstory: Agent 57 specializing in add.\n",
            "Agent Role: Agent with expertise in webdriver, Goal: Provide insights on webdriver related to the question, Backstory: Agent 58 specializing in webdriver.\n",
            "Agent Role: Agent with expertise in file, Goal: Provide insights on file related to the question, Backstory: Agent 59 specializing in file.\n",
            "Agent Role: Agent with expertise in selenium, Goal: Provide insights on selenium related to the question, Backstory: Agent 60 specializing in selenium.\n",
            "Agent Role: Agent with expertise in response, Goal: Provide insights on response related to the question, Backstory: Agent 61 specializing in response.\n",
            "Agent Role: Agent with expertise in relevant, Goal: Provide insights on relevant related to the question, Backstory: Agent 62 specializing in relevant.\n",
            "Agent Role: Agent with expertise in collected, Goal: Provide insights on collected related to the question, Backstory: Agent 63 specializing in collected.\n",
            "Agent Role: Agent with expertise in note, Goal: Provide insights on note related to the question, Backstory: Agent 64 specializing in note.\n",
            "Agent Role: Agent with expertise in libraries, Goal: Provide insights on libraries related to the question, Backstory: Agent 65 specializing in libraries.\n",
            "Agent Role: Agent with expertise in scriabin, Goal: Provide insights on scriabin related to the question, Backstory: Agent 66 specializing in scriabin.\n",
            "Agent Role: Agent with expertise in scores, Goal: Provide insights on scores related to the question, Backstory: Agent 67 specializing in scores.\n",
            "Agent Role: Agent with expertise in efficient, Goal: Provide insights on efficient related to the question, Backstory: Agent 68 specializing in efficient.\n",
            "Agent Role: Agent with expertise in follow, Goal: Provide insights on follow related to the question, Backstory: Agent 69 specializing in follow.\n",
            "Agent Role: Agent with expertise in str, Goal: Provide insights on str related to the question, Backstory: Agent 70 specializing in str.\n",
            "Agent Role: Agent with expertise in completing, Goal: Provide insights on completing related to the question, Backstory: Agent 71 specializing in completing.\n",
            "Agent Role: Agent with expertise in adherence, Goal: Provide insights on adherence related to the question, Backstory: Agent 72 specializing in adherence.\n",
            "Agent Role: Agent with expertise in rating, Goal: Provide insights on rating related to the question, Backstory: Agent 73 specializing in rating.\n",
            "Agent Role: Agent with expertise in save, Goal: Provide insights on save related to the question, Backstory: Agent 74 specializing in save.\n",
            "Agent Role: Agent with expertise in title, Goal: Provide insights on title related to the question, Backstory: Agent 75 specializing in title.\n",
            "Agent Role: Agent with expertise in returns, Goal: Provide insights on returns related to the question, Backstory: Agent 76 specializing in returns.\n",
            "Agent Role: Agent with expertise in crewai, Goal: Provide insights on crewai related to the question, Backstory: Agent 77 specializing in crewai.\n",
            "Agent Role: Agent with expertise in csv, Goal: Provide insights on csv related to the question, Backstory: Agent 78 specializing in csv.\n",
            "Agent Role: Agent with expertise in use, Goal: Provide insights on use related to the question, Backstory: Agent 79 specializing in use.\n",
            "Agent Role: Agent with expertise in script, Goal: Provide insights on script related to the question, Backstory: Agent 80 specializing in script.\n",
            "Agent Role: Agent with expertise in content, Goal: Provide insights on content related to the question, Backstory: Agent 81 specializing in content.\n",
            "Agent Role: Agent with expertise in handling, Goal: Provide insights on handling related to the question, Backstory: Agent 82 specializing in handling.\n",
            "Agent Role: Agent with expertise in tasked, Goal: Provide insights on tasked related to the question, Backstory: Agent 83 specializing in tasked.\n",
            "Agent Role: Agent with expertise in python, Goal: Provide insights on python related to the question, Backstory: Agent 84 specializing in python.\n",
            "Agent Role: Agent with expertise in dataset, Goal: Provide insights on dataset related to the question, Backstory: Agent 85 specializing in dataset.\n",
            "Agent Role: Agent with expertise in generate, Goal: Provide insights on generate related to the question, Backstory: Agent 86 specializing in generate.\n",
            "Agent Role: Agent with expertise in websites, Goal: Provide insights on websites related to the question, Backstory: Agent 87 specializing in websites.\n",
            "Agent Role: Agent with expertise in musical, Goal: Provide insights on musical related to the question, Backstory: Agent 88 specializing in musical.\n",
            "Agent Role: Agent with expertise in like, Goal: Provide insights on like related to the question, Backstory: Agent 89 specializing in like.\n",
            "Agent Role: Agent with expertise in agent, Goal: Provide insights on agent related to the question, Backstory: Agent 90 specializing in agent.\n",
            "Agent Role: Agent with expertise in dynamic, Goal: Provide insights on dynamic related to the question, Backstory: Agent 91 specializing in dynamic.\n",
            "Agent Role: Agent with expertise in composer, Goal: Provide insights on composer related to the question, Backstory: Agent 92 specializing in composer.\n",
            "Agent Role: Agent with expertise in style, Goal: Provide insights on style related to the question, Backstory: Agent 93 specializing in style.\n",
            "Agent Role: Agent with expertise in project, Goal: Provide insights on project related to the question, Backstory: Agent 94 specializing in project.\n",
            "Agent Role: Agent with expertise in http, Goal: Provide insights on http related to the question, Backstory: Agent 95 specializing in http.\n",
            "Agent Role: Agent with expertise in information, Goal: Provide insights on information related to the question, Backstory: Agent 96 specializing in information.\n",
            "Agent Role: Agent with expertise in higher, Goal: Provide insights on higher related to the question, Backstory: Agent 97 specializing in higher.\n",
            "Agent Role: Agent with expertise in print, Goal: Provide insights on print related to the question, Backstory: Agent 98 specializing in print.\n",
            "Agent Role: Agent with expertise in process, Goal: Provide insights on process related to the question, Backstory: Agent 99 specializing in process.\n",
            "Agent Role: Agent with expertise in args, Goal: Provide insights on args related to the question, Backstory: Agent 100 specializing in args.\n",
            "Agent Role: Agent with expertise in scrapes, Goal: Provide insights on scrapes related to the question, Backstory: Agent 101 specializing in scrapes.\n",
            "Agent Role: Agent with expertise in extracted, Goal: Provide insights on extracted related to the question, Backstory: Agent 102 specializing in extracted.\n",
            "Agent Role: Agent with expertise in contain, Goal: Provide insights on contain related to the question, Backstory: Agent 103 specializing in contain.\n",
            "Agent Role: Agent with expertise in main, Goal: Provide insights on main related to the question, Backstory: Agent 104 specializing in main.\n",
            "Agent Role: Agent with expertise in saving, Goal: Provide insights on saving related to the question, Backstory: Agent 105 specializing in saving.\n",
            "Agent Role: Agent with expertise in analyze, Goal: Provide insights on analyze related to the question, Backstory: Agent 106 specializing in analyze.\n",
            "Agent Role: Agent with expertise in iterate, Goal: Provide insights on iterate related to the question, Backstory: Agent 107 specializing in iterate.\n",
            "Agent Role: Agent with expertise in error, Goal: Provide insights on error related to the question, Backstory: Agent 108 specializing in error.\n",
            "Agent Role: Agent with expertise in used, Goal: Provide insights on used related to the question, Backstory: Agent 109 specializing in used.\n",
            "Agent Role: Agent with expertise in depend, Goal: Provide insights on depend related to the question, Backstory: Agent 110 specializing in depend.\n",
            "Agent Role: Agent with expertise in functionalities, Goal: Provide insights on functionalities related to the question, Backstory: Agent 111 specializing in functionalities.\n",
            "Agent Role: Agent with expertise in list, Goal: Provide insights on list related to the question, Backstory: Agent 112 specializing in list.\n",
            "Agent Role: Agent with expertise in score, Goal: Provide insights on score related to the question, Backstory: Agent 113 specializing in score.\n",
            "Agent Role: Agent with expertise in code, Goal: Provide insights on code related to the question, Backstory: Agent 114 specializing in code.\n",
            "Agent Role: Agent with expertise in primary, Goal: Provide insights on primary related to the question, Backstory: Agent 115 specializing in primary.\n",
            "Agent Role: Agent with expertise in single, Goal: Provide insights on single related to the question, Backstory: Agent 116 specializing in single.\n",
            "Agent Role: Agent with expertise in specific, Goal: Provide insights on specific related to the question, Backstory: Agent 117 specializing in specific.\n",
            "Agent Role: Agent with expertise in def, Goal: Provide insights on def related to the question, Backstory: Agent 118 specializing in def.\n",
            "Agent Role: Agent with expertise in example, Goal: Provide insights on example related to the question, Backstory: Agent 119 specializing in example.\n",
            "Agent Role: Agent with expertise in webpage, Goal: Provide insights on webpage related to the question, Backstory: Agent 120 specializing in webpage.\n",
            "Agent Role: Agent with expertise in urls, Goal: Provide insights on urls related to the question, Backstory: Agent 121 specializing in urls.\n",
            "Agent Role: Agent with expertise in request, Goal: Provide insights on request related to the question, Backstory: Agent 122 specializing in request.\n",
            "Agent Role: Agent with expertise in final, Goal: Provide insights on final related to the question, Backstory: Agent 123 specializing in final.\n",
            "Agent Role: Agent with expertise in objective, Goal: Provide insights on objective related to the question, Backstory: Agent 124 specializing in objective.\n",
            "Agent Role: Agent with expertise in make, Goal: Provide insights on make related to the question, Backstory: Agent 125 specializing in make.\n",
            "Agent Role: Agent with expertise in page, Goal: Provide insights on page related to the question, Backstory: Agent 126 specializing in page.\n",
            "Agent Role: Agent with expertise in scrape, Goal: Provide insights on scrape related to the question, Backstory: Agent 127 specializing in scrape.\n",
            "Agent Role: Agent with expertise in comprehensive, Goal: Provide insights on comprehensive related to the question, Backstory: Agent 128 specializing in comprehensive.\n",
            "Agent Role: Agent with expertise in parse, Goal: Provide insights on parse related to the question, Backstory: Agent 129 specializing in parse.\n",
            "Agent Role: Agent with expertise in aim, Goal: Provide insights on aim related to the question, Backstory: Agent 130 specializing in aim.\n",
            "Agent Role: Agent with expertise in rubric, Goal: Provide insights on rubric related to the question, Backstory: Agent 131 specializing in rubric.\n",
            "Agent Role: Agent with expertise in requests, Goal: Provide insights on requests related to the question, Backstory: Agent 132 specializing in requests.\n",
            "Agent Role: Agent with expertise in online, Goal: Provide insights on online related to the question, Backstory: Agent 133 specializing in online.\n",
            "Agent Role: Agent with expertise in beautifulsoup, Goal: Provide insights on beautifulsoup related to the question, Backstory: Agent 134 specializing in beautifulsoup.\n",
            "Agent Role: Agent with expertise in return, Goal: Provide insights on return related to the question, Backstory: Agent 135 specializing in return.\n",
            "Agent Role: Agent with expertise in url, Goal: Provide insights on url related to the question, Backstory: Agent 136 specializing in url.\n",
            "Agent Role: Agent with expertise in various, Goal: Provide insights on various related to the question, Backstory: Agent 137 specializing in various.\n",
            "Agent Role: Agent with expertise in files, Goal: Provide insights on files related to the question, Backstory: Agent 138 specializing in files.\n",
            "Agent Role: Agent with expertise in ensure, Goal: Provide insights on ensure related to the question, Backstory: Agent 139 specializing in ensure.\n",
            "Agent Role: Agent with expertise in website, Goal: Provide insights on website related to the question, Backstory: Agent 140 specializing in website.\n",
            "Agent Role: Agent with expertise in gather, Goal: Provide insights on gather related to the question, Backstory: Agent 141 specializing in gather.\n",
            "Agent Role: Agent with expertise in implement, Goal: Provide insights on implement related to the question, Backstory: Agent 142 specializing in implement.\n",
            "Agent Role: Agent with expertise in collection, Goal: Provide insights on collection related to the question, Backstory: Agent 143 specializing in collection.\n",
            "Agent Role: Agent with expertise in elements, Goal: Provide insights on elements related to the question, Backstory: Agent 144 specializing in elements.\n",
            "Agent Role: Agent with expertise in necessary, Goal: Provide insights on necessary related to the question, Backstory: Agent 145 specializing in necessary.\n",
            "Agent Role: Agent with expertise in failed, Goal: Provide insights on failed related to the question, Backstory: Agent 146 specializing in failed.\n",
            "Agent Role: Agent with expertise in import, Goal: Provide insights on import related to the question, Backstory: Agent 147 specializing in import.\n",
            "Agent Role: Agent with expertise in structure, Goal: Provide insights on structure related to the question, Backstory: Agent 148 specializing in structure.\n",
            "Agent Role: Agent with expertise in function, Goal: Provide insights on function related to the question, Backstory: Agent 149 specializing in function.\n",
            "Agent Role: Agent with expertise in midi, Goal: Provide insights on midi related to the question, Backstory: Agent 150 specializing in midi.\n",
            "Agent Role: Agent with expertise in sources, Goal: Provide insights on sources related to the question, Backstory: Agent 151 specializing in sources.\n",
            "Agent Role: Agent with expertise in extract, Goal: Provide insights on extract related to the question, Backstory: Agent 152 specializing in extract.\n",
            "Agent Role: Agent with expertise in implementations, Goal: Provide insights on implementations related to the question, Backstory: Agent 153 specializing in implementations.\n",
            "Agent Role: Agent with expertise in focusing, Goal: Provide insights on focusing related to the question, Backstory: Agent 154 specializing in focusing.\n",
            "Agent Role: Agent with expertise in processing, Goal: Provide insights on processing related to the question, Backstory: Agent 155 specializing in processing.\n",
            "Agent Role: Agent with expertise in compositions, Goal: Provide insights on compositions related to the question, Backstory: Agent 156 specializing in compositions.\n",
            "Agent Role: Agent with expertise in data, Goal: Provide insights on data related to the question, Backstory: Agent 157 specializing in data.\n",
            "Agent Role: Agent with expertise in collect, Goal: Provide insights on collect related to the question, Backstory: Agent 158 specializing in collect.\n",
            "Agent Role: Agent with expertise in given, Goal: Provide insights on given related to the question, Backstory: Agent 159 specializing in given.\n",
            "Agent Role: Agent with expertise in etc, Goal: Provide insights on etc related to the question, Backstory: Agent 160 specializing in etc.\n",
            "Agent Role: Agent with expertise in soup, Goal: Provide insights on soup related to the question, Backstory: Agent 161 specializing in soup.\n",
            "Agent Role: Agent with expertise in entry, Goal: Provide insights on entry related to the question, Backstory: Agent 162 specializing in entry.\n",
            "Agent Role: Agent with expertise in retrieve, Goal: Provide insights on retrieve related to the question, Backstory: Agent 163 specializing in retrieve.\n",
            "Agent Role: Agent with expertise in quality, Goal: Provide insights on quality related to the question, Backstory: Agent 164 specializing in quality.\n",
            "Agent Role: Agent with expertise in within, Goal: Provide insights on within related to the question, Backstory: Agent 165 specializing in within.\n",
            "Agent Role: Agent with expertise in link, Goal: Provide insights on link related to the question, Backstory: Agent 166 specializing in link.\n",
            "Agent Role: Agent with expertise in achieve, Goal: Provide insights on achieve related to the question, Backstory: Agent 167 specializing in achieve.\n",
            "Agent Role: Agent with expertise in find, Goal: Provide insights on find related to the question, Backstory: Agent 168 specializing in find.\n",
            "Agent Role: Agent with expertise in role, Goal: Provide insights on role related to the question, Backstory: Agent 169 specializing in role.\n",
            "Agent Role: Agent with expertise in guidelines, Goal: Provide insights on guidelines related to the question, Backstory: Agent 170 specializing in guidelines.\n",
            "Agent Role: Agent with expertise in f, Goal: Provide insights on f related to the question, Backstory: Agent 171 specializing in f.\n",
            "Agent Role: Agent with expertise in point, Goal: Provide insights on point related to the question, Backstory: Agent 172 specializing in point.\n",
            "Agent Role: Agent with expertise in add, Goal: Provide insights on add related to the question, Backstory: Agent 173 specializing in add.\n",
            "Agent Role: Agent with expertise in webdriver, Goal: Provide insights on webdriver related to the question, Backstory: Agent 174 specializing in webdriver.\n",
            "Agent Role: Agent with expertise in file, Goal: Provide insights on file related to the question, Backstory: Agent 175 specializing in file.\n",
            "Agent Role: Agent with expertise in selenium, Goal: Provide insights on selenium related to the question, Backstory: Agent 176 specializing in selenium.\n",
            "Agent Role: Agent with expertise in response, Goal: Provide insights on response related to the question, Backstory: Agent 177 specializing in response.\n",
            "Agent Role: Agent with expertise in relevant, Goal: Provide insights on relevant related to the question, Backstory: Agent 178 specializing in relevant.\n",
            "Agent Role: Agent with expertise in collected, Goal: Provide insights on collected related to the question, Backstory: Agent 179 specializing in collected.\n",
            "Agent Role: Agent with expertise in note, Goal: Provide insights on note related to the question, Backstory: Agent 180 specializing in note.\n",
            "Agent Role: Agent with expertise in libraries, Goal: Provide insights on libraries related to the question, Backstory: Agent 181 specializing in libraries.\n",
            "Agent Role: Agent with expertise in scriabin, Goal: Provide insights on scriabin related to the question, Backstory: Agent 182 specializing in scriabin.\n",
            "Agent Role: Agent with expertise in scores, Goal: Provide insights on scores related to the question, Backstory: Agent 183 specializing in scores.\n",
            "Agent Role: Agent with expertise in efficient, Goal: Provide insights on efficient related to the question, Backstory: Agent 184 specializing in efficient.\n",
            "Agent Role: Agent with expertise in follow, Goal: Provide insights on follow related to the question, Backstory: Agent 185 specializing in follow.\n",
            "Agent Role: Agent with expertise in str, Goal: Provide insights on str related to the question, Backstory: Agent 186 specializing in str.\n",
            "Agent Role: Agent with expertise in completing, Goal: Provide insights on completing related to the question, Backstory: Agent 187 specializing in completing.\n",
            "Agent Role: Agent with expertise in adherence, Goal: Provide insights on adherence related to the question, Backstory: Agent 188 specializing in adherence.\n",
            "Agent Role: Agent with expertise in rating, Goal: Provide insights on rating related to the question, Backstory: Agent 189 specializing in rating.\n",
            "Agent Role: Agent with expertise in save, Goal: Provide insights on save related to the question, Backstory: Agent 190 specializing in save.\n",
            "Agent Role: Agent with expertise in title, Goal: Provide insights on title related to the question, Backstory: Agent 191 specializing in title.\n",
            "Agent Role: Agent with expertise in returns, Goal: Provide insights on returns related to the question, Backstory: Agent 192 specializing in returns.\n",
            "Agent Role: Agent with expertise in crewai, Goal: Provide insights on crewai related to the question, Backstory: Agent 193 specializing in crewai.\n",
            "Agent Role: Agent with expertise in csv, Goal: Provide insights on csv related to the question, Backstory: Agent 194 specializing in csv.\n",
            "Agent Role: Agent with expertise in use, Goal: Provide insights on use related to the question, Backstory: Agent 195 specializing in use.\n",
            "Agent Role: Agent with expertise in script, Goal: Provide insights on script related to the question, Backstory: Agent 196 specializing in script.\n",
            "Agent Role: Agent with expertise in content, Goal: Provide insights on content related to the question, Backstory: Agent 197 specializing in content.\n",
            "Agent Role: Agent with expertise in handling, Goal: Provide insights on handling related to the question, Backstory: Agent 198 specializing in handling.\n",
            "Agent Role: Agent with expertise in tasked, Goal: Provide insights on tasked related to the question, Backstory: Agent 199 specializing in tasked.\n",
            "Agent Role: Wildcard Agent with Diverse Perspective, Goal: Challenge the conventional thinking and provide alternative viewpoints, Backstory: An agent known for unconventional approaches and thinking outside the box.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble the AI Crew\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "import random\n",
        "\n",
        "# Function to analyze context and question for key themes\n",
        "\n",
        "# Extracting themes\n",
        "themes_bert = extract_themes_pro_bert(text)\n",
        "themes_pro = extract_themes_pro(text)\n",
        "themes = themes_bert + themes_pro\n",
        "\n",
        "# Number of agents to create\n",
        "num_agents = 200\n",
        "\n",
        "# Creating a list to hold all agents\n",
        "agents = []\n",
        "# Loop to create each agent\n",
        "for i in range(num_agents):\n",
        "    theme_index = i % len(themes)\n",
        "    role = f'Agent with expertise in {themes[theme_index]}'\n",
        "    goal = f'Provide insights on {themes[theme_index]} related to the question'\n",
        "    backstory = f'Agent {i+1} specializing in {themes[theme_index]}.'\n",
        "\n",
        "    # Creating a wildcard agent with contrasting characteristics\n",
        "    if i == num_agents - 1:\n",
        "        role = 'Wildcard Agent with Diverse Perspective'\n",
        "        goal = 'Challenge the conventional thinking and provide alternative viewpoints'\n",
        "        backstory = 'An agent known for unconventional approaches and thinking outside the box.'\n",
        "\n",
        "    # Creating an agent\n",
        "    agent = Agent(\n",
        "        role=role,\n",
        "        goal=goal,\n",
        "        backstory=backstory,\n",
        "        verbose=True\n",
        "    )\n",
        "    agents.append(agent)\n",
        "\n",
        "# Displaying the created agents\n",
        "for agent in agents:\n",
        "    print(f'Agent Role: {agent.role}, Goal: {agent.goal}, Backstory: {agent.backstory}')\n"
      ],
      "metadata": {
        "id": "vXyD_Q46cqPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774b75b5-43f2-45a0-bb0a-d3d8c40f77a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent Role: Agent with expertise in specific, Goal: Provide insights on specific related to the question, Backstory: Agent 1 specializing in specific.\n",
            "Agent Role: Agent with expertise in def, Goal: Provide insights on def related to the question, Backstory: Agent 2 specializing in def.\n",
            "Agent Role: Agent with expertise in example, Goal: Provide insights on example related to the question, Backstory: Agent 3 specializing in example.\n",
            "Agent Role: Agent with expertise in webpage, Goal: Provide insights on webpage related to the question, Backstory: Agent 4 specializing in webpage.\n",
            "Agent Role: Agent with expertise in urls, Goal: Provide insights on urls related to the question, Backstory: Agent 5 specializing in urls.\n",
            "Agent Role: Agent with expertise in request, Goal: Provide insights on request related to the question, Backstory: Agent 6 specializing in request.\n",
            "Agent Role: Agent with expertise in final, Goal: Provide insights on final related to the question, Backstory: Agent 7 specializing in final.\n",
            "Agent Role: Agent with expertise in objective, Goal: Provide insights on objective related to the question, Backstory: Agent 8 specializing in objective.\n",
            "Agent Role: Agent with expertise in make, Goal: Provide insights on make related to the question, Backstory: Agent 9 specializing in make.\n",
            "Agent Role: Agent with expertise in page, Goal: Provide insights on page related to the question, Backstory: Agent 10 specializing in page.\n",
            "Agent Role: Agent with expertise in scrape, Goal: Provide insights on scrape related to the question, Backstory: Agent 11 specializing in scrape.\n",
            "Agent Role: Agent with expertise in comprehensive, Goal: Provide insights on comprehensive related to the question, Backstory: Agent 12 specializing in comprehensive.\n",
            "Agent Role: Agent with expertise in parse, Goal: Provide insights on parse related to the question, Backstory: Agent 13 specializing in parse.\n",
            "Agent Role: Agent with expertise in aim, Goal: Provide insights on aim related to the question, Backstory: Agent 14 specializing in aim.\n",
            "Agent Role: Agent with expertise in rubric, Goal: Provide insights on rubric related to the question, Backstory: Agent 15 specializing in rubric.\n",
            "Agent Role: Agent with expertise in requests, Goal: Provide insights on requests related to the question, Backstory: Agent 16 specializing in requests.\n",
            "Agent Role: Agent with expertise in online, Goal: Provide insights on online related to the question, Backstory: Agent 17 specializing in online.\n",
            "Agent Role: Agent with expertise in beautifulsoup, Goal: Provide insights on beautifulsoup related to the question, Backstory: Agent 18 specializing in beautifulsoup.\n",
            "Agent Role: Agent with expertise in return, Goal: Provide insights on return related to the question, Backstory: Agent 19 specializing in return.\n",
            "Agent Role: Agent with expertise in url, Goal: Provide insights on url related to the question, Backstory: Agent 20 specializing in url.\n",
            "Agent Role: Agent with expertise in various, Goal: Provide insights on various related to the question, Backstory: Agent 21 specializing in various.\n",
            "Agent Role: Agent with expertise in files, Goal: Provide insights on files related to the question, Backstory: Agent 22 specializing in files.\n",
            "Agent Role: Agent with expertise in ensure, Goal: Provide insights on ensure related to the question, Backstory: Agent 23 specializing in ensure.\n",
            "Agent Role: Agent with expertise in website, Goal: Provide insights on website related to the question, Backstory: Agent 24 specializing in website.\n",
            "Agent Role: Agent with expertise in gather, Goal: Provide insights on gather related to the question, Backstory: Agent 25 specializing in gather.\n",
            "Agent Role: Agent with expertise in implement, Goal: Provide insights on implement related to the question, Backstory: Agent 26 specializing in implement.\n",
            "Agent Role: Agent with expertise in collection, Goal: Provide insights on collection related to the question, Backstory: Agent 27 specializing in collection.\n",
            "Agent Role: Agent with expertise in elements, Goal: Provide insights on elements related to the question, Backstory: Agent 28 specializing in elements.\n",
            "Agent Role: Agent with expertise in necessary, Goal: Provide insights on necessary related to the question, Backstory: Agent 29 specializing in necessary.\n",
            "Agent Role: Agent with expertise in failed, Goal: Provide insights on failed related to the question, Backstory: Agent 30 specializing in failed.\n",
            "Agent Role: Agent with expertise in import, Goal: Provide insights on import related to the question, Backstory: Agent 31 specializing in import.\n",
            "Agent Role: Agent with expertise in structure, Goal: Provide insights on structure related to the question, Backstory: Agent 32 specializing in structure.\n",
            "Agent Role: Agent with expertise in function, Goal: Provide insights on function related to the question, Backstory: Agent 33 specializing in function.\n",
            "Agent Role: Agent with expertise in midi, Goal: Provide insights on midi related to the question, Backstory: Agent 34 specializing in midi.\n",
            "Agent Role: Agent with expertise in sources, Goal: Provide insights on sources related to the question, Backstory: Agent 35 specializing in sources.\n",
            "Agent Role: Agent with expertise in extract, Goal: Provide insights on extract related to the question, Backstory: Agent 36 specializing in extract.\n",
            "Agent Role: Agent with expertise in implementations, Goal: Provide insights on implementations related to the question, Backstory: Agent 37 specializing in implementations.\n",
            "Agent Role: Agent with expertise in focusing, Goal: Provide insights on focusing related to the question, Backstory: Agent 38 specializing in focusing.\n",
            "Agent Role: Agent with expertise in processing, Goal: Provide insights on processing related to the question, Backstory: Agent 39 specializing in processing.\n",
            "Agent Role: Agent with expertise in compositions, Goal: Provide insights on compositions related to the question, Backstory: Agent 40 specializing in compositions.\n",
            "Agent Role: Agent with expertise in data, Goal: Provide insights on data related to the question, Backstory: Agent 41 specializing in data.\n",
            "Agent Role: Agent with expertise in collect, Goal: Provide insights on collect related to the question, Backstory: Agent 42 specializing in collect.\n",
            "Agent Role: Agent with expertise in given, Goal: Provide insights on given related to the question, Backstory: Agent 43 specializing in given.\n",
            "Agent Role: Agent with expertise in etc, Goal: Provide insights on etc related to the question, Backstory: Agent 44 specializing in etc.\n",
            "Agent Role: Agent with expertise in soup, Goal: Provide insights on soup related to the question, Backstory: Agent 45 specializing in soup.\n",
            "Agent Role: Agent with expertise in entry, Goal: Provide insights on entry related to the question, Backstory: Agent 46 specializing in entry.\n",
            "Agent Role: Agent with expertise in retrieve, Goal: Provide insights on retrieve related to the question, Backstory: Agent 47 specializing in retrieve.\n",
            "Agent Role: Agent with expertise in quality, Goal: Provide insights on quality related to the question, Backstory: Agent 48 specializing in quality.\n",
            "Agent Role: Agent with expertise in within, Goal: Provide insights on within related to the question, Backstory: Agent 49 specializing in within.\n",
            "Agent Role: Agent with expertise in link, Goal: Provide insights on link related to the question, Backstory: Agent 50 specializing in link.\n",
            "Agent Role: Agent with expertise in achieve, Goal: Provide insights on achieve related to the question, Backstory: Agent 51 specializing in achieve.\n",
            "Agent Role: Agent with expertise in find, Goal: Provide insights on find related to the question, Backstory: Agent 52 specializing in find.\n",
            "Agent Role: Agent with expertise in role, Goal: Provide insights on role related to the question, Backstory: Agent 53 specializing in role.\n",
            "Agent Role: Agent with expertise in guidelines, Goal: Provide insights on guidelines related to the question, Backstory: Agent 54 specializing in guidelines.\n",
            "Agent Role: Agent with expertise in f, Goal: Provide insights on f related to the question, Backstory: Agent 55 specializing in f.\n",
            "Agent Role: Agent with expertise in point, Goal: Provide insights on point related to the question, Backstory: Agent 56 specializing in point.\n",
            "Agent Role: Agent with expertise in add, Goal: Provide insights on add related to the question, Backstory: Agent 57 specializing in add.\n",
            "Agent Role: Agent with expertise in webdriver, Goal: Provide insights on webdriver related to the question, Backstory: Agent 58 specializing in webdriver.\n",
            "Agent Role: Agent with expertise in file, Goal: Provide insights on file related to the question, Backstory: Agent 59 specializing in file.\n",
            "Agent Role: Agent with expertise in selenium, Goal: Provide insights on selenium related to the question, Backstory: Agent 60 specializing in selenium.\n",
            "Agent Role: Agent with expertise in response, Goal: Provide insights on response related to the question, Backstory: Agent 61 specializing in response.\n",
            "Agent Role: Agent with expertise in relevant, Goal: Provide insights on relevant related to the question, Backstory: Agent 62 specializing in relevant.\n",
            "Agent Role: Agent with expertise in collected, Goal: Provide insights on collected related to the question, Backstory: Agent 63 specializing in collected.\n",
            "Agent Role: Agent with expertise in note, Goal: Provide insights on note related to the question, Backstory: Agent 64 specializing in note.\n",
            "Agent Role: Agent with expertise in libraries, Goal: Provide insights on libraries related to the question, Backstory: Agent 65 specializing in libraries.\n",
            "Agent Role: Agent with expertise in scriabin, Goal: Provide insights on scriabin related to the question, Backstory: Agent 66 specializing in scriabin.\n",
            "Agent Role: Agent with expertise in scores, Goal: Provide insights on scores related to the question, Backstory: Agent 67 specializing in scores.\n",
            "Agent Role: Agent with expertise in efficient, Goal: Provide insights on efficient related to the question, Backstory: Agent 68 specializing in efficient.\n",
            "Agent Role: Agent with expertise in follow, Goal: Provide insights on follow related to the question, Backstory: Agent 69 specializing in follow.\n",
            "Agent Role: Agent with expertise in str, Goal: Provide insights on str related to the question, Backstory: Agent 70 specializing in str.\n",
            "Agent Role: Agent with expertise in completing, Goal: Provide insights on completing related to the question, Backstory: Agent 71 specializing in completing.\n",
            "Agent Role: Agent with expertise in adherence, Goal: Provide insights on adherence related to the question, Backstory: Agent 72 specializing in adherence.\n",
            "Agent Role: Agent with expertise in rating, Goal: Provide insights on rating related to the question, Backstory: Agent 73 specializing in rating.\n",
            "Agent Role: Agent with expertise in save, Goal: Provide insights on save related to the question, Backstory: Agent 74 specializing in save.\n",
            "Agent Role: Agent with expertise in title, Goal: Provide insights on title related to the question, Backstory: Agent 75 specializing in title.\n",
            "Agent Role: Agent with expertise in returns, Goal: Provide insights on returns related to the question, Backstory: Agent 76 specializing in returns.\n",
            "Agent Role: Agent with expertise in crewai, Goal: Provide insights on crewai related to the question, Backstory: Agent 77 specializing in crewai.\n",
            "Agent Role: Agent with expertise in csv, Goal: Provide insights on csv related to the question, Backstory: Agent 78 specializing in csv.\n",
            "Agent Role: Agent with expertise in use, Goal: Provide insights on use related to the question, Backstory: Agent 79 specializing in use.\n",
            "Agent Role: Agent with expertise in script, Goal: Provide insights on script related to the question, Backstory: Agent 80 specializing in script.\n",
            "Agent Role: Agent with expertise in content, Goal: Provide insights on content related to the question, Backstory: Agent 81 specializing in content.\n",
            "Agent Role: Agent with expertise in handling, Goal: Provide insights on handling related to the question, Backstory: Agent 82 specializing in handling.\n",
            "Agent Role: Agent with expertise in tasked, Goal: Provide insights on tasked related to the question, Backstory: Agent 83 specializing in tasked.\n",
            "Agent Role: Agent with expertise in python, Goal: Provide insights on python related to the question, Backstory: Agent 84 specializing in python.\n",
            "Agent Role: Agent with expertise in dataset, Goal: Provide insights on dataset related to the question, Backstory: Agent 85 specializing in dataset.\n",
            "Agent Role: Agent with expertise in generate, Goal: Provide insights on generate related to the question, Backstory: Agent 86 specializing in generate.\n",
            "Agent Role: Agent with expertise in websites, Goal: Provide insights on websites related to the question, Backstory: Agent 87 specializing in websites.\n",
            "Agent Role: Agent with expertise in musical, Goal: Provide insights on musical related to the question, Backstory: Agent 88 specializing in musical.\n",
            "Agent Role: Agent with expertise in like, Goal: Provide insights on like related to the question, Backstory: Agent 89 specializing in like.\n",
            "Agent Role: Agent with expertise in agent, Goal: Provide insights on agent related to the question, Backstory: Agent 90 specializing in agent.\n",
            "Agent Role: Agent with expertise in dynamic, Goal: Provide insights on dynamic related to the question, Backstory: Agent 91 specializing in dynamic.\n",
            "Agent Role: Agent with expertise in composer, Goal: Provide insights on composer related to the question, Backstory: Agent 92 specializing in composer.\n",
            "Agent Role: Agent with expertise in style, Goal: Provide insights on style related to the question, Backstory: Agent 93 specializing in style.\n",
            "Agent Role: Agent with expertise in project, Goal: Provide insights on project related to the question, Backstory: Agent 94 specializing in project.\n",
            "Agent Role: Agent with expertise in http, Goal: Provide insights on http related to the question, Backstory: Agent 95 specializing in http.\n",
            "Agent Role: Agent with expertise in information, Goal: Provide insights on information related to the question, Backstory: Agent 96 specializing in information.\n",
            "Agent Role: Agent with expertise in higher, Goal: Provide insights on higher related to the question, Backstory: Agent 97 specializing in higher.\n",
            "Agent Role: Agent with expertise in print, Goal: Provide insights on print related to the question, Backstory: Agent 98 specializing in print.\n",
            "Agent Role: Agent with expertise in process, Goal: Provide insights on process related to the question, Backstory: Agent 99 specializing in process.\n",
            "Agent Role: Agent with expertise in args, Goal: Provide insights on args related to the question, Backstory: Agent 100 specializing in args.\n",
            "Agent Role: Agent with expertise in scrapes, Goal: Provide insights on scrapes related to the question, Backstory: Agent 101 specializing in scrapes.\n",
            "Agent Role: Agent with expertise in extracted, Goal: Provide insights on extracted related to the question, Backstory: Agent 102 specializing in extracted.\n",
            "Agent Role: Agent with expertise in contain, Goal: Provide insights on contain related to the question, Backstory: Agent 103 specializing in contain.\n",
            "Agent Role: Agent with expertise in main, Goal: Provide insights on main related to the question, Backstory: Agent 104 specializing in main.\n",
            "Agent Role: Agent with expertise in saving, Goal: Provide insights on saving related to the question, Backstory: Agent 105 specializing in saving.\n",
            "Agent Role: Agent with expertise in analyze, Goal: Provide insights on analyze related to the question, Backstory: Agent 106 specializing in analyze.\n",
            "Agent Role: Agent with expertise in iterate, Goal: Provide insights on iterate related to the question, Backstory: Agent 107 specializing in iterate.\n",
            "Agent Role: Agent with expertise in error, Goal: Provide insights on error related to the question, Backstory: Agent 108 specializing in error.\n",
            "Agent Role: Agent with expertise in used, Goal: Provide insights on used related to the question, Backstory: Agent 109 specializing in used.\n",
            "Agent Role: Agent with expertise in depend, Goal: Provide insights on depend related to the question, Backstory: Agent 110 specializing in depend.\n",
            "Agent Role: Agent with expertise in functionalities, Goal: Provide insights on functionalities related to the question, Backstory: Agent 111 specializing in functionalities.\n",
            "Agent Role: Agent with expertise in list, Goal: Provide insights on list related to the question, Backstory: Agent 112 specializing in list.\n",
            "Agent Role: Agent with expertise in score, Goal: Provide insights on score related to the question, Backstory: Agent 113 specializing in score.\n",
            "Agent Role: Agent with expertise in code, Goal: Provide insights on code related to the question, Backstory: Agent 114 specializing in code.\n",
            "Agent Role: Agent with expertise in primary, Goal: Provide insights on primary related to the question, Backstory: Agent 115 specializing in primary.\n",
            "Agent Role: Agent with expertise in single, Goal: Provide insights on single related to the question, Backstory: Agent 116 specializing in single.\n",
            "Agent Role: Agent with expertise in specific, Goal: Provide insights on specific related to the question, Backstory: Agent 117 specializing in specific.\n",
            "Agent Role: Agent with expertise in def, Goal: Provide insights on def related to the question, Backstory: Agent 118 specializing in def.\n",
            "Agent Role: Agent with expertise in example, Goal: Provide insights on example related to the question, Backstory: Agent 119 specializing in example.\n",
            "Agent Role: Agent with expertise in webpage, Goal: Provide insights on webpage related to the question, Backstory: Agent 120 specializing in webpage.\n",
            "Agent Role: Agent with expertise in urls, Goal: Provide insights on urls related to the question, Backstory: Agent 121 specializing in urls.\n",
            "Agent Role: Agent with expertise in request, Goal: Provide insights on request related to the question, Backstory: Agent 122 specializing in request.\n",
            "Agent Role: Agent with expertise in final, Goal: Provide insights on final related to the question, Backstory: Agent 123 specializing in final.\n",
            "Agent Role: Agent with expertise in objective, Goal: Provide insights on objective related to the question, Backstory: Agent 124 specializing in objective.\n",
            "Agent Role: Agent with expertise in make, Goal: Provide insights on make related to the question, Backstory: Agent 125 specializing in make.\n",
            "Agent Role: Agent with expertise in page, Goal: Provide insights on page related to the question, Backstory: Agent 126 specializing in page.\n",
            "Agent Role: Agent with expertise in scrape, Goal: Provide insights on scrape related to the question, Backstory: Agent 127 specializing in scrape.\n",
            "Agent Role: Agent with expertise in comprehensive, Goal: Provide insights on comprehensive related to the question, Backstory: Agent 128 specializing in comprehensive.\n",
            "Agent Role: Agent with expertise in parse, Goal: Provide insights on parse related to the question, Backstory: Agent 129 specializing in parse.\n",
            "Agent Role: Agent with expertise in aim, Goal: Provide insights on aim related to the question, Backstory: Agent 130 specializing in aim.\n",
            "Agent Role: Agent with expertise in rubric, Goal: Provide insights on rubric related to the question, Backstory: Agent 131 specializing in rubric.\n",
            "Agent Role: Agent with expertise in requests, Goal: Provide insights on requests related to the question, Backstory: Agent 132 specializing in requests.\n",
            "Agent Role: Agent with expertise in online, Goal: Provide insights on online related to the question, Backstory: Agent 133 specializing in online.\n",
            "Agent Role: Agent with expertise in beautifulsoup, Goal: Provide insights on beautifulsoup related to the question, Backstory: Agent 134 specializing in beautifulsoup.\n",
            "Agent Role: Agent with expertise in return, Goal: Provide insights on return related to the question, Backstory: Agent 135 specializing in return.\n",
            "Agent Role: Agent with expertise in url, Goal: Provide insights on url related to the question, Backstory: Agent 136 specializing in url.\n",
            "Agent Role: Agent with expertise in various, Goal: Provide insights on various related to the question, Backstory: Agent 137 specializing in various.\n",
            "Agent Role: Agent with expertise in files, Goal: Provide insights on files related to the question, Backstory: Agent 138 specializing in files.\n",
            "Agent Role: Agent with expertise in ensure, Goal: Provide insights on ensure related to the question, Backstory: Agent 139 specializing in ensure.\n",
            "Agent Role: Agent with expertise in website, Goal: Provide insights on website related to the question, Backstory: Agent 140 specializing in website.\n",
            "Agent Role: Agent with expertise in gather, Goal: Provide insights on gather related to the question, Backstory: Agent 141 specializing in gather.\n",
            "Agent Role: Agent with expertise in implement, Goal: Provide insights on implement related to the question, Backstory: Agent 142 specializing in implement.\n",
            "Agent Role: Agent with expertise in collection, Goal: Provide insights on collection related to the question, Backstory: Agent 143 specializing in collection.\n",
            "Agent Role: Agent with expertise in elements, Goal: Provide insights on elements related to the question, Backstory: Agent 144 specializing in elements.\n",
            "Agent Role: Agent with expertise in necessary, Goal: Provide insights on necessary related to the question, Backstory: Agent 145 specializing in necessary.\n",
            "Agent Role: Agent with expertise in failed, Goal: Provide insights on failed related to the question, Backstory: Agent 146 specializing in failed.\n",
            "Agent Role: Agent with expertise in import, Goal: Provide insights on import related to the question, Backstory: Agent 147 specializing in import.\n",
            "Agent Role: Agent with expertise in structure, Goal: Provide insights on structure related to the question, Backstory: Agent 148 specializing in structure.\n",
            "Agent Role: Agent with expertise in function, Goal: Provide insights on function related to the question, Backstory: Agent 149 specializing in function.\n",
            "Agent Role: Agent with expertise in midi, Goal: Provide insights on midi related to the question, Backstory: Agent 150 specializing in midi.\n",
            "Agent Role: Agent with expertise in sources, Goal: Provide insights on sources related to the question, Backstory: Agent 151 specializing in sources.\n",
            "Agent Role: Agent with expertise in extract, Goal: Provide insights on extract related to the question, Backstory: Agent 152 specializing in extract.\n",
            "Agent Role: Agent with expertise in implementations, Goal: Provide insights on implementations related to the question, Backstory: Agent 153 specializing in implementations.\n",
            "Agent Role: Agent with expertise in focusing, Goal: Provide insights on focusing related to the question, Backstory: Agent 154 specializing in focusing.\n",
            "Agent Role: Agent with expertise in processing, Goal: Provide insights on processing related to the question, Backstory: Agent 155 specializing in processing.\n",
            "Agent Role: Agent with expertise in compositions, Goal: Provide insights on compositions related to the question, Backstory: Agent 156 specializing in compositions.\n",
            "Agent Role: Agent with expertise in data, Goal: Provide insights on data related to the question, Backstory: Agent 157 specializing in data.\n",
            "Agent Role: Agent with expertise in collect, Goal: Provide insights on collect related to the question, Backstory: Agent 158 specializing in collect.\n",
            "Agent Role: Agent with expertise in given, Goal: Provide insights on given related to the question, Backstory: Agent 159 specializing in given.\n",
            "Agent Role: Agent with expertise in etc, Goal: Provide insights on etc related to the question, Backstory: Agent 160 specializing in etc.\n",
            "Agent Role: Agent with expertise in soup, Goal: Provide insights on soup related to the question, Backstory: Agent 161 specializing in soup.\n",
            "Agent Role: Agent with expertise in entry, Goal: Provide insights on entry related to the question, Backstory: Agent 162 specializing in entry.\n",
            "Agent Role: Agent with expertise in retrieve, Goal: Provide insights on retrieve related to the question, Backstory: Agent 163 specializing in retrieve.\n",
            "Agent Role: Agent with expertise in quality, Goal: Provide insights on quality related to the question, Backstory: Agent 164 specializing in quality.\n",
            "Agent Role: Agent with expertise in within, Goal: Provide insights on within related to the question, Backstory: Agent 165 specializing in within.\n",
            "Agent Role: Agent with expertise in link, Goal: Provide insights on link related to the question, Backstory: Agent 166 specializing in link.\n",
            "Agent Role: Agent with expertise in achieve, Goal: Provide insights on achieve related to the question, Backstory: Agent 167 specializing in achieve.\n",
            "Agent Role: Agent with expertise in find, Goal: Provide insights on find related to the question, Backstory: Agent 168 specializing in find.\n",
            "Agent Role: Agent with expertise in role, Goal: Provide insights on role related to the question, Backstory: Agent 169 specializing in role.\n",
            "Agent Role: Agent with expertise in guidelines, Goal: Provide insights on guidelines related to the question, Backstory: Agent 170 specializing in guidelines.\n",
            "Agent Role: Agent with expertise in f, Goal: Provide insights on f related to the question, Backstory: Agent 171 specializing in f.\n",
            "Agent Role: Agent with expertise in point, Goal: Provide insights on point related to the question, Backstory: Agent 172 specializing in point.\n",
            "Agent Role: Agent with expertise in add, Goal: Provide insights on add related to the question, Backstory: Agent 173 specializing in add.\n",
            "Agent Role: Agent with expertise in webdriver, Goal: Provide insights on webdriver related to the question, Backstory: Agent 174 specializing in webdriver.\n",
            "Agent Role: Agent with expertise in file, Goal: Provide insights on file related to the question, Backstory: Agent 175 specializing in file.\n",
            "Agent Role: Agent with expertise in selenium, Goal: Provide insights on selenium related to the question, Backstory: Agent 176 specializing in selenium.\n",
            "Agent Role: Agent with expertise in response, Goal: Provide insights on response related to the question, Backstory: Agent 177 specializing in response.\n",
            "Agent Role: Agent with expertise in relevant, Goal: Provide insights on relevant related to the question, Backstory: Agent 178 specializing in relevant.\n",
            "Agent Role: Agent with expertise in collected, Goal: Provide insights on collected related to the question, Backstory: Agent 179 specializing in collected.\n",
            "Agent Role: Agent with expertise in note, Goal: Provide insights on note related to the question, Backstory: Agent 180 specializing in note.\n",
            "Agent Role: Agent with expertise in libraries, Goal: Provide insights on libraries related to the question, Backstory: Agent 181 specializing in libraries.\n",
            "Agent Role: Agent with expertise in scriabin, Goal: Provide insights on scriabin related to the question, Backstory: Agent 182 specializing in scriabin.\n",
            "Agent Role: Agent with expertise in scores, Goal: Provide insights on scores related to the question, Backstory: Agent 183 specializing in scores.\n",
            "Agent Role: Agent with expertise in efficient, Goal: Provide insights on efficient related to the question, Backstory: Agent 184 specializing in efficient.\n",
            "Agent Role: Agent with expertise in follow, Goal: Provide insights on follow related to the question, Backstory: Agent 185 specializing in follow.\n",
            "Agent Role: Agent with expertise in str, Goal: Provide insights on str related to the question, Backstory: Agent 186 specializing in str.\n",
            "Agent Role: Agent with expertise in completing, Goal: Provide insights on completing related to the question, Backstory: Agent 187 specializing in completing.\n",
            "Agent Role: Agent with expertise in adherence, Goal: Provide insights on adherence related to the question, Backstory: Agent 188 specializing in adherence.\n",
            "Agent Role: Agent with expertise in rating, Goal: Provide insights on rating related to the question, Backstory: Agent 189 specializing in rating.\n",
            "Agent Role: Agent with expertise in save, Goal: Provide insights on save related to the question, Backstory: Agent 190 specializing in save.\n",
            "Agent Role: Agent with expertise in title, Goal: Provide insights on title related to the question, Backstory: Agent 191 specializing in title.\n",
            "Agent Role: Agent with expertise in returns, Goal: Provide insights on returns related to the question, Backstory: Agent 192 specializing in returns.\n",
            "Agent Role: Agent with expertise in crewai, Goal: Provide insights on crewai related to the question, Backstory: Agent 193 specializing in crewai.\n",
            "Agent Role: Agent with expertise in csv, Goal: Provide insights on csv related to the question, Backstory: Agent 194 specializing in csv.\n",
            "Agent Role: Agent with expertise in use, Goal: Provide insights on use related to the question, Backstory: Agent 195 specializing in use.\n",
            "Agent Role: Agent with expertise in script, Goal: Provide insights on script related to the question, Backstory: Agent 196 specializing in script.\n",
            "Agent Role: Agent with expertise in content, Goal: Provide insights on content related to the question, Backstory: Agent 197 specializing in content.\n",
            "Agent Role: Agent with expertise in handling, Goal: Provide insights on handling related to the question, Backstory: Agent 198 specializing in handling.\n",
            "Agent Role: Agent with expertise in tasked, Goal: Provide insights on tasked related to the question, Backstory: Agent 199 specializing in tasked.\n",
            "Agent Role: Wildcard Agent with Diverse Perspective, Goal: Challenge the conventional thinking and provide alternative viewpoints, Backstory: An agent known for unconventional approaches and thinking outside the box.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute crew to perform the tasks\n",
        "\n",
        "# Define a task for the agents\n",
        "# This should be defined according to the specific problem at hand\n",
        "task = Task(description= text, agent=agents[0])\n",
        "\n",
        "# Create the crew with a sequential process\n",
        "crew = Crew(\n",
        "    agents=agents,\n",
        "    tasks=[task],\n",
        "    process=Process.sequential,  # Using sequential process, but can be adapted\n",
        "    verbose=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Ymg9kdIyMM5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Initialize metrics\n",
        "start_time = time.time()\n",
        "error_count = 0\n",
        "total_tasks = len(crew.tasks)  # Assuming 'crew' is your CrewAI instance\n",
        "\n",
        "# Execute CrewAI tasks\n",
        "try:\n",
        "    result = crew.kickoff()\n",
        "except Exception as e:\n",
        "    error_count += 1\n",
        "    print(f\"Error occurred: {e}\")\n",
        "\n",
        "# Calculate total time taken\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Output results\n",
        "print(f\"Total tasks: {total_tasks}\")\n",
        "print(f\"Errors: {error_count}\")\n",
        "print(f\"Total time taken: {total_time} seconds\")\n"
      ],
      "metadata": {
        "id": "WIOEjqr5Px9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f5d2f9-9789-409c-aba4-2adf6ae7332e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[DEBUG]: Working Agent: Agent with expertise in specific\n",
            "\n",
            "[INFO]: Starting Task: \n",
            "You are tasked with completing a Python script that scrapes musical scores of Scriabin's compositions from various online sources. The primary objective is to gather a comprehensive dataset that will be used to analyze Scriabin's musical style and generate MIDI files. Your role is to implement specific functionalities within the script to ensure efficient data collection and processing. Follow these guidelines:\n",
            "\n",
            "# Import necessary libraries\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "# Use Selenium if necessary for dynamic websites\n",
            "# from selenium import webdriver\n",
            "\n",
            "# Function to scrape scores from a single website\n",
            "def scrape_website(url):\n",
            "    \"\"\n",
            "    Scrapes musical scores from the given URL.\n",
            "    Args:\n",
            "    url (str): URL of the website to scrape.\n",
            "\n",
            "    Returns:\n",
            "    list: A list of musical scores and their details.\n",
            "    \"\"\n",
            "    # Add code to make an HTTP request to the website\n",
            "    response = requests.get(url)\n",
            "    \n",
            "    # Add error handling for the request\n",
            "    if response.status_code != 200:\n",
            "        print(f\"Failed to retrieve data from {url}\")\n",
            "        return []\n",
            "\n",
            "    # Parse the webpage content\n",
            "    soup = BeautifulSoup(response.text, 'html.parser')\n",
            "\n",
            "    # Add code to extract the relevant data from the page\n",
            "    # This will depend on the structure of the webpage\n",
            "    # For example, find all elements that contain score information\n",
            "    # scores = soup.find_all('...')\n",
            "\n",
            "    # Iterate over the extracted elements and collect necessary data\n",
            "    # collected_scores = []\n",
            "    # for score in scores:\n",
            "    #     # Extract data like title, composer, link to the score, etc.\n",
            "    #     # title = score.find('...').text\n",
            "    #     # Add extracted data to the collected_scores list\n",
            "    #     # collected_scores.append({...})\n",
            "\n",
            "    # Return the collected scores\n",
            "    return collected_scores\n",
            "\n",
            "# List of URLs to scrape\n",
            "urls = [\n",
            "    'https://imslp.org',\n",
            "    'https://musescore.com',\n",
            "    # Add other URLs here\n",
            "]\n",
            "\n",
            "# Main function to scrape scores from all websites\n",
            "def main():\n",
            "    all_scores = []\n",
            "    for url in urls:\n",
            "        scores = scrape_website(url)\n",
            "        all_scores.extend(scores)\n",
            "\n",
            "    # Add code to save or process the collected scores\n",
            "    # For example, saving to a CSV file\n",
            "    # save_to_csv(all_scores)\n",
            "\n",
            "    # Print or return the final collected data\n",
            "    print(all_scores)\n",
            "\n",
            "# Entry point of the script\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "\n",
            "\n",
            "Note to CrewAI Agent: This is a coding-centric project. More comprehensive and efficient code implementations will achieve higher scores. Aim for a 5-star rating by focusing on code quality and adherence to the rubric.\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "Final Answer: Here is how you can fill the missing parts to scrape musical scores from the websites:\n",
            "\n",
            "```python\n",
            "# Import necessary libraries\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "from selenium import webdriver\n",
            "\n",
            "# Function to scrape scores from a single website\n",
            "def scrape_website(url):\n",
            "    \"\"\n",
            "    Scrapes musical scores from the given URL.\n",
            "    Args:\n",
            "    url (str): URL of the website to scrape.\n",
            "\n",
            "    Returns:\n",
            "    list: A list of musical scores and their details.\n",
            "    \"\"\n",
            "    # Add code to make an HTTP request to the website\n",
            "    response = requests.get(url)\n",
            "    \n",
            "    # Add error handling for the request\n",
            "    if response.status_code != 200:\n",
            "        print(f\"Failed to retrieve data from {url}\")\n",
            "        return []\n",
            "\n",
            "    # Parse the webpage content\n",
            "    soup = BeautifulSoup(response.text, 'html.parser')\n",
            "\n",
            "    # Add code to extract the relevant data from the page\n",
            "    # This will depend on the structure of the webpage\n",
            "    # For example, find all elements that contain score information\n",
            "    scores = soup.find_all('div', class_='score-info') # Change this according to the actual website structure\n",
            "\n",
            "    # Iterate over the extracted elements and collect necessary data\n",
            "    collected_scores = []\n",
            "    for score in scores:\n",
            "        # Extract data like title, composer, link to the score, etc.\n",
            "        title = score.find('h3').text # Change this according to the actual website structure\n",
            "        composer = score.find('span', class_='composer').text # Change this according to the actual website structure\n",
            "        link = score.find('a')['href'] # Change this according to the actual website structure\n",
            "\n",
            "        # Add extracted data to the collected_scores list\n",
            "        collected_scores.append({'title': title, 'composer': composer, 'link': link})\n",
            "\n",
            "    # Return the collected scores\n",
            "    return collected_scores\n",
            "\n",
            "# List of URLs to scrape\n",
            "urls = [\n",
            "    'https://imslp.org',\n",
            "    'https://musescore.com',\n",
            "    # Add other URLs here\n",
            "]\n",
            "\n",
            "# Main function to scrape scores from all websites\n",
            "def main():\n",
            "    all_scores = []\n",
            "    for url in urls:\n",
            "        scores = scrape_website(url)\n",
            "        all_scores.extend(scores)\n",
            "\n",
            "    # Add code to save or process the collected scores\n",
            "    # For example, saving to a CSV file\n",
            "    import csv\n",
            "    keys = all_scores[0].keys()\n",
            "    with open('scores.csv', 'w', newline='') as output_file:\n",
            "        dict_writer = csv.DictWriter(output_file, keys)\n",
            "        dict_writer.writeheader()\n",
            "        dict_writer.writerows(all_scores)\n",
            "\n",
            "    # Print or return the final collected data\n",
            "    print(all_scores)\n",
            "\n",
            "# Entry point of the script\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "```\n",
            "\n",
            "Please note that this is a basic implementation, the actual implementation may vary depending on the structure of the websites you are scraping. You might need to use Selenium for websites that load content dynamically using Javascript.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "[DEBUG]: [Agent with expertise in specific] Task output: Here is how you can fill the missing parts to scrape musical scores from the websites:\n",
            "\n",
            "```python\n",
            "# Import necessary libraries\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "from selenium import webdriver\n",
            "\n",
            "# Function to scrape scores from a single website\n",
            "def scrape_website(url):\n",
            "    \"\"\n",
            "    Scrapes musical scores from the given URL.\n",
            "    Args:\n",
            "    url (str): URL of the website to scrape.\n",
            "\n",
            "    Returns:\n",
            "    list: A list of musical scores and their details.\n",
            "    \"\"\n",
            "    # Add code to make an HTTP request to the website\n",
            "    response = requests.get(url)\n",
            "    \n",
            "    # Add error handling for the request\n",
            "    if response.status_code != 200:\n",
            "        print(f\"Failed to retrieve data from {url}\")\n",
            "        return []\n",
            "\n",
            "    # Parse the webpage content\n",
            "    soup = BeautifulSoup(response.text, 'html.parser')\n",
            "\n",
            "    # Add code to extract the relevant data from the page\n",
            "    # This will depend on the structure of the webpage\n",
            "    # For example, find all elements that contain score information\n",
            "    scores = soup.find_all('div', class_='score-info') # Change this according to the actual website structure\n",
            "\n",
            "    # Iterate over the extracted elements and collect necessary data\n",
            "    collected_scores = []\n",
            "    for score in scores:\n",
            "        # Extract data like title, composer, link to the score, etc.\n",
            "        title = score.find('h3').text # Change this according to the actual website structure\n",
            "        composer = score.find('span', class_='composer').text # Change this according to the actual website structure\n",
            "        link = score.find('a')['href'] # Change this according to the actual website structure\n",
            "\n",
            "        # Add extracted data to the collected_scores list\n",
            "        collected_scores.append({'title': title, 'composer': composer, 'link': link})\n",
            "\n",
            "    # Return the collected scores\n",
            "    return collected_scores\n",
            "\n",
            "# List of URLs to scrape\n",
            "urls = [\n",
            "    'https://imslp.org',\n",
            "    'https://musescore.com',\n",
            "    # Add other URLs here\n",
            "]\n",
            "\n",
            "# Main function to scrape scores from all websites\n",
            "def main():\n",
            "    all_scores = []\n",
            "    for url in urls:\n",
            "        scores = scrape_website(url)\n",
            "        all_scores.extend(scores)\n",
            "\n",
            "    # Add code to save or process the collected scores\n",
            "    # For example, saving to a CSV file\n",
            "    import csv\n",
            "    keys = all_scores[0].keys()\n",
            "    with open('scores.csv', 'w', newline='') as output_file:\n",
            "        dict_writer = csv.DictWriter(output_file, keys)\n",
            "        dict_writer.writeheader()\n",
            "        dict_writer.writerows(all_scores)\n",
            "\n",
            "    # Print or return the final collected data\n",
            "    print(all_scores)\n",
            "\n",
            "# Entry point of the script\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "```\n",
            "\n",
            "Please note that this is a basic implementation, the actual implementation may vary depending on the structure of the websites you are scraping. You might need to use Selenium for websites that load content dynamically using Javascript.\n",
            "\n",
            "\n",
            "Total tasks: 1\n",
            "Errors: 0\n",
            "Total time taken: 90.15131378173828 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i1uByeei-fRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Initialize metrics\n",
        "start_time = time.time()\n",
        "error_count = 0\n",
        "total_tasks = len(crew.tasks)  # Assuming 'crew' is your CrewAI instance\n",
        "\n",
        "# Execute CrewAI tasks\n",
        "try:\n",
        "    result = crew.kickoff()\n",
        "except Exception as e:\n",
        "    error_count += 1\n",
        "    print(f\"Error occurred: {e}\")\n",
        "\n",
        "# Calculate total time taken\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Output results\n",
        "print(f\"Total tasks: {total_tasks}\")\n",
        "print(f\"Errors: {error_count}\")\n",
        "print(f\"Total time taken: {total_time} seconds\")\n"
      ],
      "metadata": {
        "id": "HspaX32w-iC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbafa3d0-aa97-4e58-f7ba-a6f31fd5c546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[DEBUG]: Working Agent: Agent with expertise in specific\n",
            "\n",
            "[INFO]: Starting Task: \n",
            "You are tasked with completing a Python script that scrapes musical scores of Scriabin's compositions from various online sources. The primary objective is to gather a comprehensive dataset that will be used to analyze Scriabin's musical style and generate MIDI files. Your role is to implement specific functionalities within the script to ensure efficient data collection and processing. Follow these guidelines:\n",
            "\n",
            "# Import necessary libraries\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "# Use Selenium if necessary for dynamic websites\n",
            "# from selenium import webdriver\n",
            "\n",
            "# Function to scrape scores from a single website\n",
            "def scrape_website(url):\n",
            "    \"\"\n",
            "    Scrapes musical scores from the given URL.\n",
            "    Args:\n",
            "    url (str): URL of the website to scrape.\n",
            "\n",
            "    Returns:\n",
            "    list: A list of musical scores and their details.\n",
            "    \"\"\n",
            "    # Add code to make an HTTP request to the website\n",
            "    response = requests.get(url)\n",
            "    \n",
            "    # Add error handling for the request\n",
            "    if response.status_code != 200:\n",
            "        print(f\"Failed to retrieve data from {url}\")\n",
            "        return []\n",
            "\n",
            "    # Parse the webpage content\n",
            "    soup = BeautifulSoup(response.text, 'html.parser')\n",
            "\n",
            "    # Add code to extract the relevant data from the page\n",
            "    # This will depend on the structure of the webpage\n",
            "    # For example, find all elements that contain score information\n",
            "    # scores = soup.find_all('...')\n",
            "\n",
            "    # Iterate over the extracted elements and collect necessary data\n",
            "    # collected_scores = []\n",
            "    # for score in scores:\n",
            "    #     # Extract data like title, composer, link to the score, etc.\n",
            "    #     # title = score.find('...').text\n",
            "    #     # Add extracted data to the collected_scores list\n",
            "    #     # collected_scores.append({...})\n",
            "\n",
            "    # Return the collected scores\n",
            "    return collected_scores\n",
            "\n",
            "# List of URLs to scrape\n",
            "urls = [\n",
            "    'https://imslp.org',\n",
            "    'https://musescore.com',\n",
            "    # Add other URLs here\n",
            "]\n",
            "\n",
            "# Main function to scrape scores from all websites\n",
            "def main():\n",
            "    all_scores = []\n",
            "    for url in urls:\n",
            "        scores = scrape_website(url)\n",
            "        all_scores.extend(scores)\n",
            "\n",
            "    # Add code to save or process the collected scores\n",
            "    # For example, saving to a CSV file\n",
            "    # save_to_csv(all_scores)\n",
            "\n",
            "    # Print or return the final collected data\n",
            "    print(all_scores)\n",
            "\n",
            "# Entry point of the script\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "\n",
            "\n",
            "Note to CrewAI Agent: This is a coding-centric project. More comprehensive and efficient code implementations will achieve higher scores. Aim for a 5-star rating by focusing on code quality and adherence to the rubric.\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "Final Answer: Sure, I'd recommend filling out the `scrape_website` function and the `main` function in the following way:\n",
            "\n",
            "```python\n",
            "# Import necessary libraries\n",
            "from bs4 import BeautifulSoup\n",
            "import requests\n",
            "import csv\n",
            "\n",
            "# Function to scrape scores from a single website\n",
            "def scrape_website(url):\n",
            "    \"\"\"\n",
            "    Scrapes musical scores from the given URL.\n",
            "    Args:\n",
            "    url (str): URL of the website to scrape.\n",
            "\n",
            "    Returns:\n",
            "    list: A list of musical scores and their details.\n",
            "    \"\"\"\n",
            "    try:\n",
            "        response = requests.get(url)\n",
            "        response.raise_for_status()\n",
            "    except requests.HTTPError as http_err:\n",
            "        print(f'HTTP error occurred: {http_err}')\n",
            "        return []\n",
            "    except Exception as err:\n",
            "        print(f'Other error occurred: {err}')\n",
            "        return []\n",
            "    \n",
            "    # Parse the webpage content\n",
            "    soup = BeautifulSoup(response.text, 'html.parser')\n",
            "\n",
            "    # Extract the relevant data from the page\n",
            "    # This will depend on the structure of the webpage\n",
            "    # For example, find all elements that contain score information\n",
            "    scores = soup.find_all('...')\n",
            "\n",
            "    # Iterate over the extracted elements and collect necessary data\n",
            "    collected_scores = []\n",
            "    for score in scores:\n",
            "        # Extract data like title, composer, link to the score, etc.\n",
            "        # title = score.find('...').text\n",
            "        # Add extracted data to the collected_scores list\n",
            "        # collected_scores.append({...})\n",
            "\n",
            "    # Return the collected scores\n",
            "    return collected_scores\n",
            "\n",
            "# List of URLs to scrape\n",
            "urls = [\n",
            "    'https://imslp.org',\n",
            "    'https://musescore.com',\n",
            "    # Add other URLs here\n",
            "]\n",
            "\n",
            "# Main function to scrape scores from all websites\n",
            "def main():\n",
            "    all_scores = []\n",
            "    for url in urls:\n",
            "        scores = scrape_website(url)\n",
            "        all_scores.extend(scores)\n",
            "\n",
            "    # Save the collected scores to a CSV file\n",
            "    with open('score_data.csv', 'w', newline='') as file:\n",
            "        writer = csv.writer(file)\n",
            "        writer.writerows(all_scores)\n",
            "\n",
            "    # Print the final collected data\n",
            "    print(all_scores)\n",
            "\n",
            "# Entry point of the script\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "```\n",
            "\n",
            "Please note that the code for extracting data from the pages (marked with '...') is just a placeholder. The actual implementation will depend on the structure of the webpages from which you want to scrape data. You might want to inspect the HTML of the webpages to figure out how to locate the score data.\n",
            "\n",
            "Also, I'm assuming that the scores are structured data that can be written to a CSV file. If they're not structured data, or if you want to handle them differently, you may need to modify the code that writes the scores to the CSV file.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "[DEBUG]: [Agent with expertise in specific] Task output: Sure, I'd recommend filling out the `scrape_website` function and the `main` function in the following way:\n",
            "\n",
            "```python\n",
            "# Import necessary libraries\n",
            "from bs4 import BeautifulSoup\n",
            "import requests\n",
            "import csv\n",
            "\n",
            "# Function to scrape scores from a single website\n",
            "def scrape_website(url):\n",
            "    \"\"\"\n",
            "    Scrapes musical scores from the given URL.\n",
            "    Args:\n",
            "    url (str): URL of the website to scrape.\n",
            "\n",
            "    Returns:\n",
            "    list: A list of musical scores and their details.\n",
            "    \"\"\"\n",
            "    try:\n",
            "        response = requests.get(url)\n",
            "        response.raise_for_status()\n",
            "    except requests.HTTPError as http_err:\n",
            "        print(f'HTTP error occurred: {http_err}')\n",
            "        return []\n",
            "    except Exception as err:\n",
            "        print(f'Other error occurred: {err}')\n",
            "        return []\n",
            "    \n",
            "    # Parse the webpage content\n",
            "    soup = BeautifulSoup(response.text, 'html.parser')\n",
            "\n",
            "    # Extract the relevant data from the page\n",
            "    # This will depend on the structure of the webpage\n",
            "    # For example, find all elements that contain score information\n",
            "    scores = soup.find_all('...')\n",
            "\n",
            "    # Iterate over the extracted elements and collect necessary data\n",
            "    collected_scores = []\n",
            "    for score in scores:\n",
            "        # Extract data like title, composer, link to the score, etc.\n",
            "        # title = score.find('...').text\n",
            "        # Add extracted data to the collected_scores list\n",
            "        # collected_scores.append({...})\n",
            "\n",
            "    # Return the collected scores\n",
            "    return collected_scores\n",
            "\n",
            "# List of URLs to scrape\n",
            "urls = [\n",
            "    'https://imslp.org',\n",
            "    'https://musescore.com',\n",
            "    # Add other URLs here\n",
            "]\n",
            "\n",
            "# Main function to scrape scores from all websites\n",
            "def main():\n",
            "    all_scores = []\n",
            "    for url in urls:\n",
            "        scores = scrape_website(url)\n",
            "        all_scores.extend(scores)\n",
            "\n",
            "    # Save the collected scores to a CSV file\n",
            "    with open('score_data.csv', 'w', newline='') as file:\n",
            "        writer = csv.writer(file)\n",
            "        writer.writerows(all_scores)\n",
            "\n",
            "    # Print the final collected data\n",
            "    print(all_scores)\n",
            "\n",
            "# Entry point of the script\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "```\n",
            "\n",
            "Please note that the code for extracting data from the pages (marked with '...') is just a placeholder. The actual implementation will depend on the structure of the webpages from which you want to scrape data. You might want to inspect the HTML of the webpages to figure out how to locate the score data.\n",
            "\n",
            "Also, I'm assuming that the scores are structured data that can be written to a CSV file. If they're not structured data, or if you want to handle them differently, you may need to modify the code that writes the scores to the CSV file.\n",
            "\n",
            "\n",
            "Total tasks: 1\n",
            "Errors: 0\n",
            "Total time taken: 97.47201681137085 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###CLIPBOARD BELOW TO PASTE RESPONSE###"
      ],
      "metadata": {
        "id": "8FBL8NGV-puO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
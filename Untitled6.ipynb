{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPzN47gLRCY93/ESrTvt3JI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/localecho/Python-GUI-examples/blob/master/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQc1tf7kLHBx"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# Load a pre-trained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Function to load an image from a URL\n",
        "def load_image_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    image = Image.open(requests.get(url, stream=True).raw)\n",
        "    image = F.to_tensor(image).unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "# Example image URL (Replace with your own URL or use a local image)\n",
        "image_url = \"https://thumbs.dreamstime.com/b/flat-vector-social-media-internet-infographic-icon-style-online-content-sharing-lifestyle-infographics-set-concept-collage-stylish-59052315.jpg\"\n",
        "\n",
        "\n",
        "image = load_image_from_url(image_url)\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    prediction = model(image)\n",
        "\n",
        "# Correct way to process predictions\n",
        "boxes = prediction[0]['boxes']\n",
        "labels = prediction[0]['labels']\n",
        "scores = prediction[0]['scores']\n",
        "\n",
        "# Now, you can iterate over these tensors if you need to process individual detections\n",
        "for i in range(len(boxes)):\n",
        "    box = boxes[i]\n",
        "    label = labels[i]\n",
        "    score = scores[i]\n",
        "    print(f\"Box: {box}, Label: {label}, Score: {score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib torchvision pillow openai\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key here\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "69iLQHABU_gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets Visualize\n",
        "# note to BH: you can change the threshhold at the bottom\n",
        "\n",
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Function to convert tensor to PIL Image\n",
        "def tensor_to_pil(tensor):\n",
        "    return T.ToPILImage()(tensor.squeeze_(0))\n",
        "\n",
        "# Assuming 'image' is your PIL Image and 'prediction' is the output from the model\n",
        "img = tensor_to_pil(image)  # Convert the tensor image back to PIL Image if necessary\n",
        "\n",
        "# Create a matplotlib figure\n",
        "fig, ax = plt.subplots(1, figsize=(12, 9))\n",
        "ax.imshow(img)\n",
        "\n",
        "# Retrieve the COCO categories from a pre-defined list or file\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
        "    'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass',\n",
        "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
        "    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "# Continuing from the previously defined object_attributes dictionary\n",
        "object_attributes = {\n",
        "    '__background__': {\n",
        "    'bottle': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'wine glass': {'emotion': 'neutral', 'age': 'new', 'color': 'clear'},\n",
        "    'cup': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'fork': {'emotion': 'neutral', 'age': 'variable', 'color': 'silver'},\n",
        "    'knife': {'emotion': 'neutral', 'age': 'variable', 'color': 'silver'},\n",
        "    'spoon': {'emotion': 'neutral', 'age': 'variable', 'color': 'silver'},\n",
        "    'bowl': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'banana': {'emotion': 'happy', 'age': 'ripe', 'color': 'yellow'},\n",
        "    'apple': {'emotion': 'happy', 'age': 'fresh', 'color': 'red/green'},\n",
        "    'sandwich': {'emotion': 'neutral', 'age': 'fresh', 'color': 'variable'},\n",
        "    'orange': {'emotion': 'happy', 'age': 'ripe', 'color': 'orange'},\n",
        "    'broccoli': {'emotion': 'neutral', 'age': 'fresh', 'color': 'green'},\n",
        "    'carrot': {'emotion': 'happy', 'age': 'fresh', 'color': 'orange'},\n",
        "    'hot dog': {'emotion': 'happy', 'age': 'cooked', 'color': 'variable'},\n",
        "    'pizza': {'emotion': 'happy', 'age': 'cooked', 'color': 'variable'},\n",
        "    'donut': {'emotion': 'happy', 'age': 'fresh', 'color': 'variable'},\n",
        "    'cake': {'emotion': 'happy', 'age': 'fresh', 'color': 'variable'},\n",
        "    'chair': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'couch': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'potted plant': {'emotion': 'happy', 'age': 'growing', 'color': 'green'},\n",
        "    'bed': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'dining table': {'emotion': 'neutral', 'age': 'variable', 'color': 'brown'},\n",
        "    'toilet': {'emotion': 'neutral', 'age': 'variable', 'color': 'white'},\n",
        "    'tv': {'emotion': 'neutral', 'age': 'new', 'color': 'black'},\n",
        "    'laptop': {'emotion': 'neutral', 'age': 'new', 'color': 'silver/black'},\n",
        "    'mouse': {'emotion': 'neutral', 'age': 'new', 'color': 'black'},\n",
        "    'remote': {'emotion': 'neutral', 'age': 'variable', 'color': 'black'},\n",
        "    'keyboard': {'emotion': 'neutral', 'age': 'new', 'color': 'black'},\n",
        "    'cell phone': {'emotion': 'neutral', 'age': 'new', 'color': 'black'},\n",
        "    'microwave': {'emotion': 'neutral', 'age': 'new', 'color': 'silver'},\n",
        "    'oven': {'emotion': 'neutral', 'age': 'variable', 'color': 'black/silver'},\n",
        "    'toaster': {'emotion': 'neutral', 'age': 'new', 'color': 'silver'},\n",
        "    'sink': {'emotion': 'neutral', 'age': 'variable', 'color': 'silver'},\n",
        "    'refrigerator': {'emotion': 'neutral', 'age': 'new', 'color': 'white/silver'},\n",
        "    'book': {'emotion': 'happy', 'age': 'variable', 'color': 'variable'},\n",
        "    'clock': {'emotion': 'neutral', 'age': 'variable', 'color': 'variable'},\n",
        "    'vase': {'emotion': 'neutral', 'age': 'new', 'color': 'variable'},\n",
        "    'scissors': {'emotion': 'neutral', 'age': 'new', 'color': 'silver'},\n",
        "    'teddy bear': {'emotion': 'happy', 'age': 'new', 'color': 'brown'},\n",
        "    'hair drier': {'emotion': 'neutral', 'age': 'new', 'color': 'black'},\n",
        "    'toothbrush': {'emotion': 'neutral', 'age': 'new', 'color': 'variable'},\n",
        "}}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Loop through each detection in the prediction\n",
        "for box, label, score in zip(prediction[0]['boxes'], prediction[0]['labels'], prediction[0]['scores']):\n",
        "    if score > 0.1:  # Filter out detections with low confidence\n",
        "        x, y, xmax, ymax = box\n",
        "        rect = patches.Rectangle((x, y), xmax - x, ymax - y, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x, y, f\"{COCO_INSTANCE_CATEGORY_NAMES[label]}: {score:.2f}\", verticalalignment='top', color='white', fontsize=12, weight='bold', backgroundcolor=\"r\")\n",
        "\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PziOcM07Mb3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial setup for a UML diagram (text-based representation)\n",
        "\n",
        "\n",
        "detected_objects = []\n",
        "confidence_threshold = 0.1  # Adjust this threshold as needed\n",
        "\n",
        "for box, label, score in zip(prediction[0]['boxes'], prediction[0]['labels'], prediction[0]['scores']):\n",
        "    if score > confidence_threshold:\n",
        "        detected_objects.append({\n",
        "            \"name\": COCO_INSTANCE_CATEGORY_NAMES[label],\n",
        "            \"confidence\": score.item()  # Convert to Python number if it's a tensor\n",
        "        })\n",
        "\n",
        "# Example print to verify detected objects\n",
        "for obj in detected_objects:\n",
        "    print(f\"Detected {obj['name']} with confidence {obj['confidence']:.2f}\")\n"
      ],
      "metadata": {
        "id": "eUl1IFoCT3Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial setup for a UML diagram (text-based representation)\n",
        "uml_classes = {obj['name']: {\"attributes\": []} for obj in detected_objects}\n",
        "\n",
        "def generate_uml_text(uml_classes):\n",
        "    uml_text = \"classDiagram\\n\"\n",
        "    for obj_name, details in uml_classes.items():\n",
        "        uml_text += f\"    class {obj_name} {{\\n\"\n",
        "        for attr in details[\"attributes\"]:\n",
        "            uml_text += f\"        {attr}\\n\"\n",
        "        uml_text += \"    }\\n\"\n",
        "    return uml_text\n",
        "\n",
        "# Generate and print initial UML diagram structure\n",
        "uml_text = generate_uml_text(uml_classes)\n",
        "print(uml_text)\n"
      ],
      "metadata": {
        "id": "VX5DBiGYUTT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Function to generate attributes for each detected object using OpenAI API\n",
        "def get_attributes_for_object(obj_name):\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\",  # Ensure this is the current model available\n",
        "            prompt=f\"List attributes for a {obj_name}:\",\n",
        "            temperature=0.5,\n",
        "            max_tokens=60,\n",
        "            top_p=1.0,\n",
        "            frequency_penalty=0.0,\n",
        "            presence_penalty=0.0\n",
        "        )\n",
        "        # Process the response to extract attributes\n",
        "        attributes = response['choices'][0]['text'].strip().split(\", \")\n",
        "        return attributes\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "# Assuming these are the detected objects from your model\n",
        "detected_objects = [\"Dog\", \"Cat\", \"Tree\"]  # Example detected objects\n",
        "\n",
        "# Initialize a dictionary to hold the UML classes and their attributes\n",
        "uml_classes = {}\n",
        "\n",
        "# Populate the UML classes dictionary with attributes for each detected object\n",
        "for obj in detected_objects:\n",
        "    attributes = get_attributes_for_object(obj)\n",
        "    uml_classes[obj] = {\"attributes\": attributes}\n",
        "\n",
        "# Function to generate UML text representation\n",
        "def generate_uml_text(uml_classes):\n",
        "    uml_text = \"classDiagram\\n\"\n",
        "    for obj_name, details in uml_classes.items():\n",
        "        uml_text += f\"    class {obj_name} {{\\n\"\n",
        "        for attr in details[\"attributes\"]:\n",
        "            uml_text += f\"        {attr}\\n\"\n",
        "        uml_text += \"    }\\n\"\n",
        "    return uml_text\n",
        "\n",
        "# Generate and print the UML diagram text representation\n",
        "uml_text = generate_uml_text(uml_classes)\n",
        "print(uml_text)\n"
      ],
      "metadata": {
        "id": "SmFadNhnUZta"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}